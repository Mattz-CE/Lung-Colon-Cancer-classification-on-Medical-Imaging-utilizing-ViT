{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 20.0,
  "eval_steps": 500,
  "global_step": 5320,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.03759398496240601,
      "grad_norm": 9.14085865020752,
      "learning_rate": 0.0009981203007518797,
      "loss": 3.7477,
      "step": 10
    },
    {
      "epoch": 0.07518796992481203,
      "grad_norm": 5.870156288146973,
      "learning_rate": 0.0009962406015037594,
      "loss": 1.2532,
      "step": 20
    },
    {
      "epoch": 0.11278195488721804,
      "grad_norm": 4.240124702453613,
      "learning_rate": 0.000994360902255639,
      "loss": 1.0864,
      "step": 30
    },
    {
      "epoch": 0.15037593984962405,
      "grad_norm": 29.962116241455078,
      "learning_rate": 0.0009924812030075187,
      "loss": 1.0856,
      "step": 40
    },
    {
      "epoch": 0.18796992481203006,
      "grad_norm": 2.5896525382995605,
      "learning_rate": 0.0009906015037593986,
      "loss": 1.0572,
      "step": 50
    },
    {
      "epoch": 0.22556390977443608,
      "grad_norm": 3.094230890274048,
      "learning_rate": 0.0009887218045112783,
      "loss": 0.8032,
      "step": 60
    },
    {
      "epoch": 0.2631578947368421,
      "grad_norm": 9.169755935668945,
      "learning_rate": 0.000986842105263158,
      "loss": 0.8698,
      "step": 70
    },
    {
      "epoch": 0.3007518796992481,
      "grad_norm": 5.294750690460205,
      "learning_rate": 0.0009849624060150376,
      "loss": 0.664,
      "step": 80
    },
    {
      "epoch": 0.3383458646616541,
      "grad_norm": 4.074839115142822,
      "learning_rate": 0.0009830827067669173,
      "loss": 0.6667,
      "step": 90
    },
    {
      "epoch": 0.37593984962406013,
      "grad_norm": 2.102306604385376,
      "learning_rate": 0.000981203007518797,
      "loss": 0.5642,
      "step": 100
    },
    {
      "epoch": 0.41353383458646614,
      "grad_norm": 2.6693317890167236,
      "learning_rate": 0.0009793233082706768,
      "loss": 0.7794,
      "step": 110
    },
    {
      "epoch": 0.45112781954887216,
      "grad_norm": 4.604259490966797,
      "learning_rate": 0.0009774436090225563,
      "loss": 0.7088,
      "step": 120
    },
    {
      "epoch": 0.48872180451127817,
      "grad_norm": 3.9525837898254395,
      "learning_rate": 0.0009755639097744361,
      "loss": 0.6298,
      "step": 130
    },
    {
      "epoch": 0.5263157894736842,
      "grad_norm": 2.669433116912842,
      "learning_rate": 0.0009736842105263158,
      "loss": 0.5346,
      "step": 140
    },
    {
      "epoch": 0.5639097744360902,
      "grad_norm": 2.545001745223999,
      "learning_rate": 0.0009718045112781955,
      "loss": 0.5904,
      "step": 150
    },
    {
      "epoch": 0.6015037593984962,
      "grad_norm": 3.526374578475952,
      "learning_rate": 0.0009699248120300752,
      "loss": 0.6513,
      "step": 160
    },
    {
      "epoch": 0.6390977443609023,
      "grad_norm": 3.311704635620117,
      "learning_rate": 0.000968045112781955,
      "loss": 0.5574,
      "step": 170
    },
    {
      "epoch": 0.6766917293233082,
      "grad_norm": 5.68442440032959,
      "learning_rate": 0.0009661654135338346,
      "loss": 0.5324,
      "step": 180
    },
    {
      "epoch": 0.7142857142857143,
      "grad_norm": 1.4690812826156616,
      "learning_rate": 0.0009642857142857143,
      "loss": 0.5348,
      "step": 190
    },
    {
      "epoch": 0.7518796992481203,
      "grad_norm": 2.45180082321167,
      "learning_rate": 0.000962406015037594,
      "loss": 0.596,
      "step": 200
    },
    {
      "epoch": 0.7894736842105263,
      "grad_norm": 2.3034350872039795,
      "learning_rate": 0.0009605263157894737,
      "loss": 0.543,
      "step": 210
    },
    {
      "epoch": 0.8270676691729323,
      "grad_norm": 5.3512444496154785,
      "learning_rate": 0.0009586466165413534,
      "loss": 0.5433,
      "step": 220
    },
    {
      "epoch": 0.8646616541353384,
      "grad_norm": 3.7063515186309814,
      "learning_rate": 0.0009567669172932331,
      "loss": 0.5447,
      "step": 230
    },
    {
      "epoch": 0.9022556390977443,
      "grad_norm": 3.6057188510894775,
      "learning_rate": 0.0009548872180451129,
      "loss": 0.5445,
      "step": 240
    },
    {
      "epoch": 0.9398496240601504,
      "grad_norm": 3.395174741744995,
      "learning_rate": 0.0009530075187969925,
      "loss": 0.5121,
      "step": 250
    },
    {
      "epoch": 0.9774436090225563,
      "grad_norm": 3.096679449081421,
      "learning_rate": 0.0009511278195488722,
      "loss": 0.5541,
      "step": 260
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.7276666666666667,
      "eval_loss": 0.6525542140007019,
      "eval_runtime": 22.3465,
      "eval_samples_per_second": 134.249,
      "eval_steps_per_second": 8.413,
      "step": 266
    },
    {
      "epoch": 1.0150375939849625,
      "grad_norm": 2.6890029907226562,
      "learning_rate": 0.0009492481203007519,
      "loss": 0.6239,
      "step": 270
    },
    {
      "epoch": 1.0526315789473684,
      "grad_norm": 3.4130873680114746,
      "learning_rate": 0.0009473684210526315,
      "loss": 0.5247,
      "step": 280
    },
    {
      "epoch": 1.0902255639097744,
      "grad_norm": 2.838060140609741,
      "learning_rate": 0.0009454887218045113,
      "loss": 0.4933,
      "step": 290
    },
    {
      "epoch": 1.1278195488721805,
      "grad_norm": 4.915441989898682,
      "learning_rate": 0.000943609022556391,
      "loss": 0.5152,
      "step": 300
    },
    {
      "epoch": 1.1654135338345863,
      "grad_norm": 2.7924787998199463,
      "learning_rate": 0.0009417293233082707,
      "loss": 0.586,
      "step": 310
    },
    {
      "epoch": 1.2030075187969924,
      "grad_norm": 1.9953982830047607,
      "learning_rate": 0.0009398496240601504,
      "loss": 0.4929,
      "step": 320
    },
    {
      "epoch": 1.2406015037593985,
      "grad_norm": 4.549849510192871,
      "learning_rate": 0.0009379699248120301,
      "loss": 0.5577,
      "step": 330
    },
    {
      "epoch": 1.2781954887218046,
      "grad_norm": 2.286996364593506,
      "learning_rate": 0.0009360902255639098,
      "loss": 0.5093,
      "step": 340
    },
    {
      "epoch": 1.3157894736842106,
      "grad_norm": 1.7124916315078735,
      "learning_rate": 0.0009342105263157896,
      "loss": 0.5239,
      "step": 350
    },
    {
      "epoch": 1.3533834586466165,
      "grad_norm": 2.630885124206543,
      "learning_rate": 0.0009323308270676691,
      "loss": 0.5466,
      "step": 360
    },
    {
      "epoch": 1.3909774436090225,
      "grad_norm": 0.964931309223175,
      "learning_rate": 0.0009304511278195489,
      "loss": 0.5149,
      "step": 370
    },
    {
      "epoch": 1.4285714285714286,
      "grad_norm": 4.895188808441162,
      "learning_rate": 0.0009285714285714287,
      "loss": 0.4867,
      "step": 380
    },
    {
      "epoch": 1.4661654135338344,
      "grad_norm": 4.043739318847656,
      "learning_rate": 0.0009266917293233082,
      "loss": 0.6277,
      "step": 390
    },
    {
      "epoch": 1.5037593984962405,
      "grad_norm": 5.4702372550964355,
      "learning_rate": 0.000924812030075188,
      "loss": 0.6226,
      "step": 400
    },
    {
      "epoch": 1.5413533834586466,
      "grad_norm": 3.4610908031463623,
      "learning_rate": 0.0009229323308270678,
      "loss": 0.5878,
      "step": 410
    },
    {
      "epoch": 1.5789473684210527,
      "grad_norm": 3.0842177867889404,
      "learning_rate": 0.0009210526315789473,
      "loss": 0.4981,
      "step": 420
    },
    {
      "epoch": 1.6165413533834587,
      "grad_norm": 2.432703733444214,
      "learning_rate": 0.0009191729323308271,
      "loss": 0.5043,
      "step": 430
    },
    {
      "epoch": 1.6541353383458648,
      "grad_norm": 4.602102756500244,
      "learning_rate": 0.0009172932330827067,
      "loss": 0.4867,
      "step": 440
    },
    {
      "epoch": 1.6917293233082706,
      "grad_norm": 0.7171246409416199,
      "learning_rate": 0.0009154135338345865,
      "loss": 0.453,
      "step": 450
    },
    {
      "epoch": 1.7293233082706767,
      "grad_norm": 3.8302125930786133,
      "learning_rate": 0.0009135338345864662,
      "loss": 0.4533,
      "step": 460
    },
    {
      "epoch": 1.7669172932330826,
      "grad_norm": 2.633589267730713,
      "learning_rate": 0.0009116541353383458,
      "loss": 0.5227,
      "step": 470
    },
    {
      "epoch": 1.8045112781954886,
      "grad_norm": 1.1934527158737183,
      "learning_rate": 0.0009097744360902256,
      "loss": 0.5179,
      "step": 480
    },
    {
      "epoch": 1.8421052631578947,
      "grad_norm": 1.3497748374938965,
      "learning_rate": 0.0009078947368421054,
      "loss": 0.4239,
      "step": 490
    },
    {
      "epoch": 1.8796992481203008,
      "grad_norm": 2.1659934520721436,
      "learning_rate": 0.0009060150375939849,
      "loss": 0.4507,
      "step": 500
    },
    {
      "epoch": 1.9172932330827068,
      "grad_norm": 3.074089288711548,
      "learning_rate": 0.0009041353383458647,
      "loss": 0.5833,
      "step": 510
    },
    {
      "epoch": 1.954887218045113,
      "grad_norm": 1.5850797891616821,
      "learning_rate": 0.0009022556390977444,
      "loss": 0.5121,
      "step": 520
    },
    {
      "epoch": 1.9924812030075187,
      "grad_norm": 3.9894611835479736,
      "learning_rate": 0.000900375939849624,
      "loss": 0.4421,
      "step": 530
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.7706666666666667,
      "eval_loss": 0.5131775736808777,
      "eval_runtime": 22.4163,
      "eval_samples_per_second": 133.831,
      "eval_steps_per_second": 8.387,
      "step": 532
    },
    {
      "epoch": 2.030075187969925,
      "grad_norm": 3.431629180908203,
      "learning_rate": 0.0008984962406015038,
      "loss": 0.5253,
      "step": 540
    },
    {
      "epoch": 2.0676691729323307,
      "grad_norm": 3.965557098388672,
      "learning_rate": 0.0008966165413533835,
      "loss": 0.5226,
      "step": 550
    },
    {
      "epoch": 2.1052631578947367,
      "grad_norm": 2.862056255340576,
      "learning_rate": 0.0008947368421052632,
      "loss": 0.5563,
      "step": 560
    },
    {
      "epoch": 2.142857142857143,
      "grad_norm": 2.011955499649048,
      "learning_rate": 0.0008928571428571429,
      "loss": 0.5014,
      "step": 570
    },
    {
      "epoch": 2.180451127819549,
      "grad_norm": 3.089935779571533,
      "learning_rate": 0.0008909774436090225,
      "loss": 0.5077,
      "step": 580
    },
    {
      "epoch": 2.218045112781955,
      "grad_norm": 2.9190447330474854,
      "learning_rate": 0.0008890977443609023,
      "loss": 0.5385,
      "step": 590
    },
    {
      "epoch": 2.255639097744361,
      "grad_norm": 1.5257513523101807,
      "learning_rate": 0.000887218045112782,
      "loss": 0.5072,
      "step": 600
    },
    {
      "epoch": 2.293233082706767,
      "grad_norm": 3.1222879886627197,
      "learning_rate": 0.0008853383458646616,
      "loss": 0.4584,
      "step": 610
    },
    {
      "epoch": 2.3308270676691727,
      "grad_norm": 1.7052481174468994,
      "learning_rate": 0.0008834586466165414,
      "loss": 0.4926,
      "step": 620
    },
    {
      "epoch": 2.3684210526315788,
      "grad_norm": 2.408006191253662,
      "learning_rate": 0.0008815789473684211,
      "loss": 0.5012,
      "step": 630
    },
    {
      "epoch": 2.406015037593985,
      "grad_norm": 1.6382815837860107,
      "learning_rate": 0.0008796992481203007,
      "loss": 0.4097,
      "step": 640
    },
    {
      "epoch": 2.443609022556391,
      "grad_norm": 1.296998143196106,
      "learning_rate": 0.0008778195488721805,
      "loss": 0.4498,
      "step": 650
    },
    {
      "epoch": 2.481203007518797,
      "grad_norm": 0.8661569356918335,
      "learning_rate": 0.0008759398496240602,
      "loss": 0.4859,
      "step": 660
    },
    {
      "epoch": 2.518796992481203,
      "grad_norm": 2.630949020385742,
      "learning_rate": 0.0008740601503759399,
      "loss": 0.4371,
      "step": 670
    },
    {
      "epoch": 2.556390977443609,
      "grad_norm": 3.041748046875,
      "learning_rate": 0.0008721804511278195,
      "loss": 0.4506,
      "step": 680
    },
    {
      "epoch": 2.593984962406015,
      "grad_norm": 2.2811782360076904,
      "learning_rate": 0.0008703007518796993,
      "loss": 0.5779,
      "step": 690
    },
    {
      "epoch": 2.6315789473684212,
      "grad_norm": 2.1491708755493164,
      "learning_rate": 0.000868421052631579,
      "loss": 0.5496,
      "step": 700
    },
    {
      "epoch": 2.6691729323308273,
      "grad_norm": 2.4146575927734375,
      "learning_rate": 0.0008665413533834586,
      "loss": 0.4543,
      "step": 710
    },
    {
      "epoch": 2.706766917293233,
      "grad_norm": 4.777310848236084,
      "learning_rate": 0.0008646616541353384,
      "loss": 0.4881,
      "step": 720
    },
    {
      "epoch": 2.744360902255639,
      "grad_norm": 2.293078899383545,
      "learning_rate": 0.0008627819548872181,
      "loss": 0.4649,
      "step": 730
    },
    {
      "epoch": 2.781954887218045,
      "grad_norm": 2.354982852935791,
      "learning_rate": 0.0008609022556390978,
      "loss": 0.4975,
      "step": 740
    },
    {
      "epoch": 2.819548872180451,
      "grad_norm": 4.58906888961792,
      "learning_rate": 0.0008590225563909775,
      "loss": 0.5407,
      "step": 750
    },
    {
      "epoch": 2.857142857142857,
      "grad_norm": 3.7180426120758057,
      "learning_rate": 0.0008571428571428571,
      "loss": 0.5073,
      "step": 760
    },
    {
      "epoch": 2.8947368421052633,
      "grad_norm": 3.714195489883423,
      "learning_rate": 0.0008552631578947369,
      "loss": 0.4919,
      "step": 770
    },
    {
      "epoch": 2.932330827067669,
      "grad_norm": 1.7935913801193237,
      "learning_rate": 0.0008533834586466165,
      "loss": 0.4897,
      "step": 780
    },
    {
      "epoch": 2.969924812030075,
      "grad_norm": 2.466808557510376,
      "learning_rate": 0.0008515037593984962,
      "loss": 0.4562,
      "step": 790
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.7426666666666667,
      "eval_loss": 0.5665432214736938,
      "eval_runtime": 24.9432,
      "eval_samples_per_second": 120.273,
      "eval_steps_per_second": 7.537,
      "step": 798
    },
    {
      "epoch": 3.007518796992481,
      "grad_norm": 4.324301719665527,
      "learning_rate": 0.000849624060150376,
      "loss": 0.4363,
      "step": 800
    },
    {
      "epoch": 3.045112781954887,
      "grad_norm": 3.243647575378418,
      "learning_rate": 0.0008477443609022557,
      "loss": 0.4651,
      "step": 810
    },
    {
      "epoch": 3.082706766917293,
      "grad_norm": 1.6373406648635864,
      "learning_rate": 0.0008458646616541353,
      "loss": 0.4424,
      "step": 820
    },
    {
      "epoch": 3.1203007518796992,
      "grad_norm": 1.9434645175933838,
      "learning_rate": 0.0008439849624060151,
      "loss": 0.4793,
      "step": 830
    },
    {
      "epoch": 3.1578947368421053,
      "grad_norm": 1.341678500175476,
      "learning_rate": 0.0008421052631578947,
      "loss": 0.4467,
      "step": 840
    },
    {
      "epoch": 3.1954887218045114,
      "grad_norm": 0.7910569310188293,
      "learning_rate": 0.0008402255639097745,
      "loss": 0.4109,
      "step": 850
    },
    {
      "epoch": 3.2330827067669174,
      "grad_norm": 2.2796952724456787,
      "learning_rate": 0.0008383458646616542,
      "loss": 0.5037,
      "step": 860
    },
    {
      "epoch": 3.2706766917293235,
      "grad_norm": 3.5937564373016357,
      "learning_rate": 0.0008364661654135338,
      "loss": 0.5262,
      "step": 870
    },
    {
      "epoch": 3.308270676691729,
      "grad_norm": 3.4168386459350586,
      "learning_rate": 0.0008345864661654136,
      "loss": 0.4907,
      "step": 880
    },
    {
      "epoch": 3.345864661654135,
      "grad_norm": 0.898300051689148,
      "learning_rate": 0.0008327067669172933,
      "loss": 0.4303,
      "step": 890
    },
    {
      "epoch": 3.3834586466165413,
      "grad_norm": 4.233138561248779,
      "learning_rate": 0.0008308270676691729,
      "loss": 0.4181,
      "step": 900
    },
    {
      "epoch": 3.4210526315789473,
      "grad_norm": 1.9652225971221924,
      "learning_rate": 0.0008289473684210527,
      "loss": 0.5284,
      "step": 910
    },
    {
      "epoch": 3.4586466165413534,
      "grad_norm": 2.8604040145874023,
      "learning_rate": 0.0008270676691729323,
      "loss": 0.4171,
      "step": 920
    },
    {
      "epoch": 3.4962406015037595,
      "grad_norm": 2.359283208847046,
      "learning_rate": 0.000825187969924812,
      "loss": 0.4443,
      "step": 930
    },
    {
      "epoch": 3.5338345864661656,
      "grad_norm": 1.3890204429626465,
      "learning_rate": 0.0008233082706766918,
      "loss": 0.5123,
      "step": 940
    },
    {
      "epoch": 3.571428571428571,
      "grad_norm": 1.2302744388580322,
      "learning_rate": 0.0008214285714285714,
      "loss": 0.4668,
      "step": 950
    },
    {
      "epoch": 3.6090225563909772,
      "grad_norm": 8.040719032287598,
      "learning_rate": 0.0008195488721804511,
      "loss": 0.4963,
      "step": 960
    },
    {
      "epoch": 3.6466165413533833,
      "grad_norm": 2.306572914123535,
      "learning_rate": 0.0008176691729323309,
      "loss": 0.5382,
      "step": 970
    },
    {
      "epoch": 3.6842105263157894,
      "grad_norm": 1.882021188735962,
      "learning_rate": 0.0008157894736842105,
      "loss": 0.4199,
      "step": 980
    },
    {
      "epoch": 3.7218045112781954,
      "grad_norm": 1.58681321144104,
      "learning_rate": 0.0008139097744360903,
      "loss": 0.4606,
      "step": 990
    },
    {
      "epoch": 3.7593984962406015,
      "grad_norm": 2.2933592796325684,
      "learning_rate": 0.0008120300751879699,
      "loss": 0.5208,
      "step": 1000
    },
    {
      "epoch": 3.7969924812030076,
      "grad_norm": 1.8875246047973633,
      "learning_rate": 0.0008101503759398496,
      "loss": 0.4197,
      "step": 1010
    },
    {
      "epoch": 3.8345864661654137,
      "grad_norm": 1.5488560199737549,
      "learning_rate": 0.0008082706766917294,
      "loss": 0.5135,
      "step": 1020
    },
    {
      "epoch": 3.8721804511278197,
      "grad_norm": 3.1046805381774902,
      "learning_rate": 0.000806390977443609,
      "loss": 0.5226,
      "step": 1030
    },
    {
      "epoch": 3.909774436090226,
      "grad_norm": 3.696600914001465,
      "learning_rate": 0.0008045112781954887,
      "loss": 0.453,
      "step": 1040
    },
    {
      "epoch": 3.9473684210526314,
      "grad_norm": 2.6951217651367188,
      "learning_rate": 0.0008026315789473685,
      "loss": 0.4607,
      "step": 1050
    },
    {
      "epoch": 3.9849624060150375,
      "grad_norm": 2.8384814262390137,
      "learning_rate": 0.0008007518796992482,
      "loss": 0.4693,
      "step": 1060
    },
    {
      "epoch": 4.0,
      "eval_accuracy": 0.8003333333333333,
      "eval_loss": 0.44087594747543335,
      "eval_runtime": 23.2243,
      "eval_samples_per_second": 129.175,
      "eval_steps_per_second": 8.095,
      "step": 1064
    },
    {
      "epoch": 4.022556390977444,
      "grad_norm": 3.32171368598938,
      "learning_rate": 0.0007988721804511278,
      "loss": 0.3949,
      "step": 1070
    },
    {
      "epoch": 4.06015037593985,
      "grad_norm": 3.5129904747009277,
      "learning_rate": 0.0007969924812030075,
      "loss": 0.4146,
      "step": 1080
    },
    {
      "epoch": 4.097744360902255,
      "grad_norm": 1.3127343654632568,
      "learning_rate": 0.0007951127819548872,
      "loss": 0.4755,
      "step": 1090
    },
    {
      "epoch": 4.135338345864661,
      "grad_norm": 4.088782787322998,
      "learning_rate": 0.000793233082706767,
      "loss": 0.4376,
      "step": 1100
    },
    {
      "epoch": 4.172932330827067,
      "grad_norm": 4.038374423980713,
      "learning_rate": 0.0007913533834586466,
      "loss": 0.4205,
      "step": 1110
    },
    {
      "epoch": 4.2105263157894735,
      "grad_norm": 1.8155372142791748,
      "learning_rate": 0.0007894736842105263,
      "loss": 0.4584,
      "step": 1120
    },
    {
      "epoch": 4.2481203007518795,
      "grad_norm": 2.9581234455108643,
      "learning_rate": 0.0007875939849624061,
      "loss": 0.4024,
      "step": 1130
    },
    {
      "epoch": 4.285714285714286,
      "grad_norm": 1.6799803972244263,
      "learning_rate": 0.0007857142857142857,
      "loss": 0.46,
      "step": 1140
    },
    {
      "epoch": 4.323308270676692,
      "grad_norm": 2.0289435386657715,
      "learning_rate": 0.0007838345864661654,
      "loss": 0.4761,
      "step": 1150
    },
    {
      "epoch": 4.360902255639098,
      "grad_norm": 2.398808240890503,
      "learning_rate": 0.0007819548872180451,
      "loss": 0.4499,
      "step": 1160
    },
    {
      "epoch": 4.398496240601504,
      "grad_norm": 4.2011284828186035,
      "learning_rate": 0.0007800751879699249,
      "loss": 0.4655,
      "step": 1170
    },
    {
      "epoch": 4.43609022556391,
      "grad_norm": 4.284480094909668,
      "learning_rate": 0.0007781954887218045,
      "loss": 0.5432,
      "step": 1180
    },
    {
      "epoch": 4.473684210526316,
      "grad_norm": 0.6654775738716125,
      "learning_rate": 0.0007763157894736842,
      "loss": 0.4794,
      "step": 1190
    },
    {
      "epoch": 4.511278195488722,
      "grad_norm": 1.547709345817566,
      "learning_rate": 0.000774436090225564,
      "loss": 0.4727,
      "step": 1200
    },
    {
      "epoch": 4.548872180451128,
      "grad_norm": 1.829198956489563,
      "learning_rate": 0.0007725563909774437,
      "loss": 0.4089,
      "step": 1210
    },
    {
      "epoch": 4.586466165413534,
      "grad_norm": 3.33678936958313,
      "learning_rate": 0.0007706766917293233,
      "loss": 0.4523,
      "step": 1220
    },
    {
      "epoch": 4.62406015037594,
      "grad_norm": 2.477782726287842,
      "learning_rate": 0.0007687969924812031,
      "loss": 0.4448,
      "step": 1230
    },
    {
      "epoch": 4.661654135338345,
      "grad_norm": 2.2501397132873535,
      "learning_rate": 0.0007669172932330827,
      "loss": 0.4106,
      "step": 1240
    },
    {
      "epoch": 4.6992481203007515,
      "grad_norm": 4.282168388366699,
      "learning_rate": 0.0007650375939849624,
      "loss": 0.4884,
      "step": 1250
    },
    {
      "epoch": 4.7368421052631575,
      "grad_norm": 2.4860119819641113,
      "learning_rate": 0.0007631578947368421,
      "loss": 0.4329,
      "step": 1260
    },
    {
      "epoch": 4.774436090225564,
      "grad_norm": 1.4084261655807495,
      "learning_rate": 0.0007612781954887218,
      "loss": 0.4276,
      "step": 1270
    },
    {
      "epoch": 4.81203007518797,
      "grad_norm": 0.7204952239990234,
      "learning_rate": 0.0007593984962406016,
      "loss": 0.4019,
      "step": 1280
    },
    {
      "epoch": 4.849624060150376,
      "grad_norm": 0.7160332202911377,
      "learning_rate": 0.0007575187969924812,
      "loss": 0.4094,
      "step": 1290
    },
    {
      "epoch": 4.887218045112782,
      "grad_norm": 1.3620049953460693,
      "learning_rate": 0.0007556390977443609,
      "loss": 0.4598,
      "step": 1300
    },
    {
      "epoch": 4.924812030075188,
      "grad_norm": 1.4498077630996704,
      "learning_rate": 0.0007537593984962407,
      "loss": 0.4476,
      "step": 1310
    },
    {
      "epoch": 4.962406015037594,
      "grad_norm": 1.821528673171997,
      "learning_rate": 0.0007518796992481202,
      "loss": 0.4281,
      "step": 1320
    },
    {
      "epoch": 5.0,
      "grad_norm": 1.5571777820587158,
      "learning_rate": 0.00075,
      "loss": 0.4551,
      "step": 1330
    },
    {
      "epoch": 5.0,
      "eval_accuracy": 0.7873333333333333,
      "eval_loss": 0.4939522445201874,
      "eval_runtime": 25.0436,
      "eval_samples_per_second": 119.791,
      "eval_steps_per_second": 7.507,
      "step": 1330
    },
    {
      "epoch": 5.037593984962406,
      "grad_norm": 3.228053331375122,
      "learning_rate": 0.0007481203007518798,
      "loss": 0.4638,
      "step": 1340
    },
    {
      "epoch": 5.075187969924812,
      "grad_norm": 1.9313836097717285,
      "learning_rate": 0.0007462406015037594,
      "loss": 0.4323,
      "step": 1350
    },
    {
      "epoch": 5.112781954887218,
      "grad_norm": 0.9940361976623535,
      "learning_rate": 0.0007443609022556391,
      "loss": 0.3922,
      "step": 1360
    },
    {
      "epoch": 5.150375939849624,
      "grad_norm": 2.009453296661377,
      "learning_rate": 0.0007424812030075188,
      "loss": 0.4073,
      "step": 1370
    },
    {
      "epoch": 5.18796992481203,
      "grad_norm": 1.2043248414993286,
      "learning_rate": 0.0007406015037593985,
      "loss": 0.5275,
      "step": 1380
    },
    {
      "epoch": 5.225563909774436,
      "grad_norm": 3.507336139678955,
      "learning_rate": 0.0007387218045112783,
      "loss": 0.4001,
      "step": 1390
    },
    {
      "epoch": 5.2631578947368425,
      "grad_norm": 1.333663821220398,
      "learning_rate": 0.0007368421052631579,
      "loss": 0.4911,
      "step": 1400
    },
    {
      "epoch": 5.3007518796992485,
      "grad_norm": 2.4176955223083496,
      "learning_rate": 0.0007349624060150376,
      "loss": 0.4419,
      "step": 1410
    },
    {
      "epoch": 5.338345864661654,
      "grad_norm": 2.9450623989105225,
      "learning_rate": 0.0007330827067669174,
      "loss": 0.4389,
      "step": 1420
    },
    {
      "epoch": 5.37593984962406,
      "grad_norm": 0.7006009221076965,
      "learning_rate": 0.0007312030075187969,
      "loss": 0.3747,
      "step": 1430
    },
    {
      "epoch": 5.413533834586466,
      "grad_norm": 0.5178288221359253,
      "learning_rate": 0.0007293233082706767,
      "loss": 0.3841,
      "step": 1440
    },
    {
      "epoch": 5.451127819548872,
      "grad_norm": 0.9962760806083679,
      "learning_rate": 0.0007274436090225564,
      "loss": 0.4081,
      "step": 1450
    },
    {
      "epoch": 5.488721804511278,
      "grad_norm": 3.138241767883301,
      "learning_rate": 0.000725563909774436,
      "loss": 0.3751,
      "step": 1460
    },
    {
      "epoch": 5.526315789473684,
      "grad_norm": 1.587256908416748,
      "learning_rate": 0.0007236842105263158,
      "loss": 0.4495,
      "step": 1470
    },
    {
      "epoch": 5.56390977443609,
      "grad_norm": 1.8656686544418335,
      "learning_rate": 0.0007218045112781955,
      "loss": 0.421,
      "step": 1480
    },
    {
      "epoch": 5.601503759398496,
      "grad_norm": 1.7686173915863037,
      "learning_rate": 0.0007199248120300752,
      "loss": 0.4489,
      "step": 1490
    },
    {
      "epoch": 5.639097744360902,
      "grad_norm": 1.7380306720733643,
      "learning_rate": 0.0007180451127819549,
      "loss": 0.4127,
      "step": 1500
    },
    {
      "epoch": 5.676691729323308,
      "grad_norm": 2.3081419467926025,
      "learning_rate": 0.0007161654135338346,
      "loss": 0.4432,
      "step": 1510
    },
    {
      "epoch": 5.714285714285714,
      "grad_norm": 3.0637974739074707,
      "learning_rate": 0.0007142857142857143,
      "loss": 0.4223,
      "step": 1520
    },
    {
      "epoch": 5.7518796992481205,
      "grad_norm": 2.1846275329589844,
      "learning_rate": 0.000712406015037594,
      "loss": 0.4381,
      "step": 1530
    },
    {
      "epoch": 5.7894736842105265,
      "grad_norm": 1.471929907798767,
      "learning_rate": 0.0007105263157894737,
      "loss": 0.4514,
      "step": 1540
    },
    {
      "epoch": 5.827067669172933,
      "grad_norm": 2.1519598960876465,
      "learning_rate": 0.0007086466165413534,
      "loss": 0.4328,
      "step": 1550
    },
    {
      "epoch": 5.864661654135339,
      "grad_norm": 4.0315423011779785,
      "learning_rate": 0.0007067669172932331,
      "loss": 0.5438,
      "step": 1560
    },
    {
      "epoch": 5.902255639097744,
      "grad_norm": 1.698701024055481,
      "learning_rate": 0.0007048872180451129,
      "loss": 0.4386,
      "step": 1570
    },
    {
      "epoch": 5.93984962406015,
      "grad_norm": 2.393162250518799,
      "learning_rate": 0.0007030075187969925,
      "loss": 0.3684,
      "step": 1580
    },
    {
      "epoch": 5.977443609022556,
      "grad_norm": 2.0870466232299805,
      "learning_rate": 0.0007011278195488722,
      "loss": 0.4238,
      "step": 1590
    },
    {
      "epoch": 6.0,
      "eval_accuracy": 0.809,
      "eval_loss": 0.4783627390861511,
      "eval_runtime": 22.2215,
      "eval_samples_per_second": 135.005,
      "eval_steps_per_second": 8.46,
      "step": 1596
    },
    {
      "epoch": 6.015037593984962,
      "grad_norm": 2.9941604137420654,
      "learning_rate": 0.0006992481203007519,
      "loss": 0.4376,
      "step": 1600
    },
    {
      "epoch": 6.052631578947368,
      "grad_norm": 1.4993664026260376,
      "learning_rate": 0.0006973684210526315,
      "loss": 0.5126,
      "step": 1610
    },
    {
      "epoch": 6.090225563909774,
      "grad_norm": 3.3063433170318604,
      "learning_rate": 0.0006954887218045113,
      "loss": 0.4726,
      "step": 1620
    },
    {
      "epoch": 6.12781954887218,
      "grad_norm": 3.7816410064697266,
      "learning_rate": 0.000693609022556391,
      "loss": 0.47,
      "step": 1630
    },
    {
      "epoch": 6.165413533834586,
      "grad_norm": 3.293837070465088,
      "learning_rate": 0.0006917293233082706,
      "loss": 0.441,
      "step": 1640
    },
    {
      "epoch": 6.203007518796992,
      "grad_norm": 1.719709873199463,
      "learning_rate": 0.0006898496240601504,
      "loss": 0.4764,
      "step": 1650
    },
    {
      "epoch": 6.2406015037593985,
      "grad_norm": 1.6892826557159424,
      "learning_rate": 0.0006879699248120301,
      "loss": 0.4989,
      "step": 1660
    },
    {
      "epoch": 6.2781954887218046,
      "grad_norm": 1.6378731727600098,
      "learning_rate": 0.0006860902255639098,
      "loss": 0.4359,
      "step": 1670
    },
    {
      "epoch": 6.315789473684211,
      "grad_norm": 3.246987819671631,
      "learning_rate": 0.0006842105263157895,
      "loss": 0.4793,
      "step": 1680
    },
    {
      "epoch": 6.353383458646617,
      "grad_norm": 2.6330606937408447,
      "learning_rate": 0.0006823308270676691,
      "loss": 0.513,
      "step": 1690
    },
    {
      "epoch": 6.390977443609023,
      "grad_norm": 3.2119638919830322,
      "learning_rate": 0.0006804511278195489,
      "loss": 0.4835,
      "step": 1700
    },
    {
      "epoch": 6.428571428571429,
      "grad_norm": 1.6158860921859741,
      "learning_rate": 0.0006785714285714287,
      "loss": 0.4463,
      "step": 1710
    },
    {
      "epoch": 6.466165413533835,
      "grad_norm": 1.9111796617507935,
      "learning_rate": 0.0006766917293233082,
      "loss": 0.4355,
      "step": 1720
    },
    {
      "epoch": 6.503759398496241,
      "grad_norm": 2.1921231746673584,
      "learning_rate": 0.000674812030075188,
      "loss": 0.4094,
      "step": 1730
    },
    {
      "epoch": 6.541353383458647,
      "grad_norm": 1.0238295793533325,
      "learning_rate": 0.0006729323308270678,
      "loss": 0.4519,
      "step": 1740
    },
    {
      "epoch": 6.578947368421053,
      "grad_norm": 1.7303366661071777,
      "learning_rate": 0.0006710526315789473,
      "loss": 0.3555,
      "step": 1750
    },
    {
      "epoch": 6.616541353383458,
      "grad_norm": 0.9923252463340759,
      "learning_rate": 0.0006691729323308271,
      "loss": 0.4377,
      "step": 1760
    },
    {
      "epoch": 6.654135338345864,
      "grad_norm": 1.5178496837615967,
      "learning_rate": 0.0006672932330827067,
      "loss": 0.3707,
      "step": 1770
    },
    {
      "epoch": 6.69172932330827,
      "grad_norm": 2.794154405593872,
      "learning_rate": 0.0006654135338345865,
      "loss": 0.4335,
      "step": 1780
    },
    {
      "epoch": 6.7293233082706765,
      "grad_norm": 2.655745267868042,
      "learning_rate": 0.0006635338345864662,
      "loss": 0.4424,
      "step": 1790
    },
    {
      "epoch": 6.7669172932330826,
      "grad_norm": 2.4094650745391846,
      "learning_rate": 0.0006616541353383458,
      "loss": 0.4874,
      "step": 1800
    },
    {
      "epoch": 6.804511278195489,
      "grad_norm": 2.0048298835754395,
      "learning_rate": 0.0006597744360902256,
      "loss": 0.4055,
      "step": 1810
    },
    {
      "epoch": 6.842105263157895,
      "grad_norm": 0.6321716904640198,
      "learning_rate": 0.0006578947368421054,
      "loss": 0.4372,
      "step": 1820
    },
    {
      "epoch": 6.879699248120301,
      "grad_norm": 1.2798978090286255,
      "learning_rate": 0.0006560150375939849,
      "loss": 0.387,
      "step": 1830
    },
    {
      "epoch": 6.917293233082707,
      "grad_norm": 2.9884657859802246,
      "learning_rate": 0.0006541353383458647,
      "loss": 0.4084,
      "step": 1840
    },
    {
      "epoch": 6.954887218045113,
      "grad_norm": 1.873381495475769,
      "learning_rate": 0.0006522556390977444,
      "loss": 0.3897,
      "step": 1850
    },
    {
      "epoch": 6.992481203007519,
      "grad_norm": 0.7596237063407898,
      "learning_rate": 0.000650375939849624,
      "loss": 0.4255,
      "step": 1860
    },
    {
      "epoch": 7.0,
      "eval_accuracy": 0.8113333333333334,
      "eval_loss": 0.41318070888519287,
      "eval_runtime": 22.9788,
      "eval_samples_per_second": 130.555,
      "eval_steps_per_second": 8.181,
      "step": 1862
    },
    {
      "epoch": 7.030075187969925,
      "grad_norm": 2.313971757888794,
      "learning_rate": 0.0006484962406015038,
      "loss": 0.3924,
      "step": 1870
    },
    {
      "epoch": 7.067669172932331,
      "grad_norm": 1.9879242181777954,
      "learning_rate": 0.0006466165413533835,
      "loss": 0.4658,
      "step": 1880
    },
    {
      "epoch": 7.105263157894737,
      "grad_norm": 1.2687729597091675,
      "learning_rate": 0.0006447368421052632,
      "loss": 0.4179,
      "step": 1890
    },
    {
      "epoch": 7.142857142857143,
      "grad_norm": 2.8152852058410645,
      "learning_rate": 0.0006428571428571429,
      "loss": 0.4269,
      "step": 1900
    },
    {
      "epoch": 7.180451127819548,
      "grad_norm": 2.507556200027466,
      "learning_rate": 0.0006409774436090225,
      "loss": 0.3888,
      "step": 1910
    },
    {
      "epoch": 7.2180451127819545,
      "grad_norm": 2.325385332107544,
      "learning_rate": 0.0006390977443609023,
      "loss": 0.3995,
      "step": 1920
    },
    {
      "epoch": 7.2556390977443606,
      "grad_norm": 1.0039894580841064,
      "learning_rate": 0.0006372180451127819,
      "loss": 0.4082,
      "step": 1930
    },
    {
      "epoch": 7.293233082706767,
      "grad_norm": 1.2593865394592285,
      "learning_rate": 0.0006353383458646616,
      "loss": 0.4238,
      "step": 1940
    },
    {
      "epoch": 7.330827067669173,
      "grad_norm": 2.0449917316436768,
      "learning_rate": 0.0006334586466165414,
      "loss": 0.3738,
      "step": 1950
    },
    {
      "epoch": 7.368421052631579,
      "grad_norm": 1.1756607294082642,
      "learning_rate": 0.0006315789473684211,
      "loss": 0.4283,
      "step": 1960
    },
    {
      "epoch": 7.406015037593985,
      "grad_norm": 2.635514497756958,
      "learning_rate": 0.0006296992481203007,
      "loss": 0.4045,
      "step": 1970
    },
    {
      "epoch": 7.443609022556391,
      "grad_norm": 1.979864239692688,
      "learning_rate": 0.0006278195488721805,
      "loss": 0.4472,
      "step": 1980
    },
    {
      "epoch": 7.481203007518797,
      "grad_norm": 2.728123426437378,
      "learning_rate": 0.0006259398496240602,
      "loss": 0.4587,
      "step": 1990
    },
    {
      "epoch": 7.518796992481203,
      "grad_norm": 2.6033389568328857,
      "learning_rate": 0.0006240601503759398,
      "loss": 0.4846,
      "step": 2000
    },
    {
      "epoch": 7.556390977443609,
      "grad_norm": 1.3970457315444946,
      "learning_rate": 0.0006221804511278195,
      "loss": 0.4304,
      "step": 2010
    },
    {
      "epoch": 7.593984962406015,
      "grad_norm": 1.220376968383789,
      "learning_rate": 0.0006203007518796993,
      "loss": 0.3902,
      "step": 2020
    },
    {
      "epoch": 7.631578947368421,
      "grad_norm": 1.6714640855789185,
      "learning_rate": 0.000618421052631579,
      "loss": 0.375,
      "step": 2030
    },
    {
      "epoch": 7.669172932330827,
      "grad_norm": 3.834604024887085,
      "learning_rate": 0.0006165413533834586,
      "loss": 0.4003,
      "step": 2040
    },
    {
      "epoch": 7.706766917293233,
      "grad_norm": 2.4021596908569336,
      "learning_rate": 0.0006146616541353384,
      "loss": 0.3738,
      "step": 2050
    },
    {
      "epoch": 7.7443609022556394,
      "grad_norm": 2.3583884239196777,
      "learning_rate": 0.0006127819548872181,
      "loss": 0.4166,
      "step": 2060
    },
    {
      "epoch": 7.7819548872180455,
      "grad_norm": 1.3035107851028442,
      "learning_rate": 0.0006109022556390978,
      "loss": 0.4091,
      "step": 2070
    },
    {
      "epoch": 7.819548872180452,
      "grad_norm": 1.3990041017532349,
      "learning_rate": 0.0006090225563909775,
      "loss": 0.4053,
      "step": 2080
    },
    {
      "epoch": 7.857142857142857,
      "grad_norm": 2.104609489440918,
      "learning_rate": 0.0006071428571428571,
      "loss": 0.3835,
      "step": 2090
    },
    {
      "epoch": 7.894736842105263,
      "grad_norm": 1.3790411949157715,
      "learning_rate": 0.0006052631578947369,
      "loss": 0.4177,
      "step": 2100
    },
    {
      "epoch": 7.932330827067669,
      "grad_norm": 1.4751873016357422,
      "learning_rate": 0.0006033834586466165,
      "loss": 0.3945,
      "step": 2110
    },
    {
      "epoch": 7.969924812030075,
      "grad_norm": 1.371779441833496,
      "learning_rate": 0.0006015037593984962,
      "loss": 0.4043,
      "step": 2120
    },
    {
      "epoch": 8.0,
      "eval_accuracy": 0.801,
      "eval_loss": 0.4160730242729187,
      "eval_runtime": 23.8837,
      "eval_samples_per_second": 125.609,
      "eval_steps_per_second": 7.871,
      "step": 2128
    },
    {
      "epoch": 8.007518796992482,
      "grad_norm": 0.9149208664894104,
      "learning_rate": 0.000599624060150376,
      "loss": 0.3621,
      "step": 2130
    },
    {
      "epoch": 8.045112781954888,
      "grad_norm": 2.7155885696411133,
      "learning_rate": 0.0005977443609022557,
      "loss": 0.4146,
      "step": 2140
    },
    {
      "epoch": 8.082706766917294,
      "grad_norm": 4.162968158721924,
      "learning_rate": 0.0005958646616541353,
      "loss": 0.4323,
      "step": 2150
    },
    {
      "epoch": 8.1203007518797,
      "grad_norm": 1.0496538877487183,
      "learning_rate": 0.0005939849624060151,
      "loss": 0.4166,
      "step": 2160
    },
    {
      "epoch": 8.157894736842104,
      "grad_norm": 2.680098295211792,
      "learning_rate": 0.0005921052631578947,
      "loss": 0.3572,
      "step": 2170
    },
    {
      "epoch": 8.19548872180451,
      "grad_norm": 2.146805763244629,
      "learning_rate": 0.0005902255639097744,
      "loss": 0.4382,
      "step": 2180
    },
    {
      "epoch": 8.233082706766917,
      "grad_norm": 2.013228416442871,
      "learning_rate": 0.0005883458646616542,
      "loss": 0.3667,
      "step": 2190
    },
    {
      "epoch": 8.270676691729323,
      "grad_norm": 2.5411293506622314,
      "learning_rate": 0.0005864661654135338,
      "loss": 0.3576,
      "step": 2200
    },
    {
      "epoch": 8.308270676691729,
      "grad_norm": 1.4246271848678589,
      "learning_rate": 0.0005845864661654136,
      "loss": 0.4006,
      "step": 2210
    },
    {
      "epoch": 8.345864661654135,
      "grad_norm": 1.6902356147766113,
      "learning_rate": 0.0005827067669172933,
      "loss": 0.4172,
      "step": 2220
    },
    {
      "epoch": 8.38345864661654,
      "grad_norm": 1.8972090482711792,
      "learning_rate": 0.0005808270676691729,
      "loss": 0.4078,
      "step": 2230
    },
    {
      "epoch": 8.421052631578947,
      "grad_norm": 1.2513970136642456,
      "learning_rate": 0.0005789473684210527,
      "loss": 0.3904,
      "step": 2240
    },
    {
      "epoch": 8.458646616541353,
      "grad_norm": 1.6895558834075928,
      "learning_rate": 0.0005770676691729322,
      "loss": 0.3873,
      "step": 2250
    },
    {
      "epoch": 8.496240601503759,
      "grad_norm": 2.0583600997924805,
      "learning_rate": 0.000575187969924812,
      "loss": 0.4029,
      "step": 2260
    },
    {
      "epoch": 8.533834586466165,
      "grad_norm": 2.2958364486694336,
      "learning_rate": 0.0005733082706766918,
      "loss": 0.451,
      "step": 2270
    },
    {
      "epoch": 8.571428571428571,
      "grad_norm": 1.6288416385650635,
      "learning_rate": 0.0005714285714285714,
      "loss": 0.4092,
      "step": 2280
    },
    {
      "epoch": 8.609022556390977,
      "grad_norm": 1.285787582397461,
      "learning_rate": 0.0005695488721804511,
      "loss": 0.3547,
      "step": 2290
    },
    {
      "epoch": 8.646616541353383,
      "grad_norm": 2.103631019592285,
      "learning_rate": 0.0005676691729323309,
      "loss": 0.3713,
      "step": 2300
    },
    {
      "epoch": 8.68421052631579,
      "grad_norm": 1.4071096181869507,
      "learning_rate": 0.0005657894736842105,
      "loss": 0.4044,
      "step": 2310
    },
    {
      "epoch": 8.721804511278195,
      "grad_norm": 1.2355968952178955,
      "learning_rate": 0.0005639097744360903,
      "loss": 0.4139,
      "step": 2320
    },
    {
      "epoch": 8.759398496240602,
      "grad_norm": 1.090121865272522,
      "learning_rate": 0.0005620300751879699,
      "loss": 0.4042,
      "step": 2330
    },
    {
      "epoch": 8.796992481203008,
      "grad_norm": 3.0760324001312256,
      "learning_rate": 0.0005601503759398496,
      "loss": 0.4106,
      "step": 2340
    },
    {
      "epoch": 8.834586466165414,
      "grad_norm": 2.880749225616455,
      "learning_rate": 0.0005582706766917294,
      "loss": 0.4644,
      "step": 2350
    },
    {
      "epoch": 8.87218045112782,
      "grad_norm": 2.121976613998413,
      "learning_rate": 0.000556390977443609,
      "loss": 0.438,
      "step": 2360
    },
    {
      "epoch": 8.909774436090226,
      "grad_norm": 1.4229881763458252,
      "learning_rate": 0.0005545112781954887,
      "loss": 0.3987,
      "step": 2370
    },
    {
      "epoch": 8.947368421052632,
      "grad_norm": 1.2502628564834595,
      "learning_rate": 0.0005526315789473685,
      "loss": 0.3858,
      "step": 2380
    },
    {
      "epoch": 8.984962406015038,
      "grad_norm": 1.9818745851516724,
      "learning_rate": 0.0005507518796992482,
      "loss": 0.428,
      "step": 2390
    },
    {
      "epoch": 9.0,
      "eval_accuracy": 0.825,
      "eval_loss": 0.39665666222572327,
      "eval_runtime": 22.369,
      "eval_samples_per_second": 134.114,
      "eval_steps_per_second": 8.404,
      "step": 2394
    },
    {
      "epoch": 9.022556390977444,
      "grad_norm": 1.4532562494277954,
      "learning_rate": 0.0005488721804511278,
      "loss": 0.38,
      "step": 2400
    },
    {
      "epoch": 9.06015037593985,
      "grad_norm": 2.7528979778289795,
      "learning_rate": 0.0005469924812030075,
      "loss": 0.3681,
      "step": 2410
    },
    {
      "epoch": 9.097744360902256,
      "grad_norm": 2.036389112472534,
      "learning_rate": 0.0005451127819548872,
      "loss": 0.4064,
      "step": 2420
    },
    {
      "epoch": 9.135338345864662,
      "grad_norm": 2.0272204875946045,
      "learning_rate": 0.000543233082706767,
      "loss": 0.4343,
      "step": 2430
    },
    {
      "epoch": 9.172932330827068,
      "grad_norm": 2.2106711864471436,
      "learning_rate": 0.0005413533834586466,
      "loss": 0.4064,
      "step": 2440
    },
    {
      "epoch": 9.210526315789474,
      "grad_norm": 2.1713500022888184,
      "learning_rate": 0.0005394736842105263,
      "loss": 0.3854,
      "step": 2450
    },
    {
      "epoch": 9.24812030075188,
      "grad_norm": 1.122231125831604,
      "learning_rate": 0.0005375939849624061,
      "loss": 0.4224,
      "step": 2460
    },
    {
      "epoch": 9.285714285714286,
      "grad_norm": 3.3135080337524414,
      "learning_rate": 0.0005357142857142857,
      "loss": 0.442,
      "step": 2470
    },
    {
      "epoch": 9.323308270676693,
      "grad_norm": 0.922620952129364,
      "learning_rate": 0.0005338345864661654,
      "loss": 0.3635,
      "step": 2480
    },
    {
      "epoch": 9.360902255639097,
      "grad_norm": 1.319167137145996,
      "learning_rate": 0.0005319548872180451,
      "loss": 0.3464,
      "step": 2490
    },
    {
      "epoch": 9.398496240601503,
      "grad_norm": 1.4682948589324951,
      "learning_rate": 0.0005300751879699249,
      "loss": 0.4336,
      "step": 2500
    },
    {
      "epoch": 9.436090225563909,
      "grad_norm": 2.370380401611328,
      "learning_rate": 0.0005281954887218045,
      "loss": 0.404,
      "step": 2510
    },
    {
      "epoch": 9.473684210526315,
      "grad_norm": 1.4480252265930176,
      "learning_rate": 0.0005263157894736842,
      "loss": 0.4142,
      "step": 2520
    },
    {
      "epoch": 9.511278195488721,
      "grad_norm": 1.4461979866027832,
      "learning_rate": 0.000524436090225564,
      "loss": 0.3571,
      "step": 2530
    },
    {
      "epoch": 9.548872180451127,
      "grad_norm": 0.8491945862770081,
      "learning_rate": 0.0005225563909774436,
      "loss": 0.3461,
      "step": 2540
    },
    {
      "epoch": 9.586466165413533,
      "grad_norm": 1.2527929544448853,
      "learning_rate": 0.0005206766917293233,
      "loss": 0.3609,
      "step": 2550
    },
    {
      "epoch": 9.62406015037594,
      "grad_norm": 2.064997911453247,
      "learning_rate": 0.0005187969924812031,
      "loss": 0.4061,
      "step": 2560
    },
    {
      "epoch": 9.661654135338345,
      "grad_norm": 1.4438964128494263,
      "learning_rate": 0.0005169172932330827,
      "loss": 0.3704,
      "step": 2570
    },
    {
      "epoch": 9.699248120300751,
      "grad_norm": 1.3435304164886475,
      "learning_rate": 0.0005150375939849624,
      "loss": 0.3732,
      "step": 2580
    },
    {
      "epoch": 9.736842105263158,
      "grad_norm": 2.4450297355651855,
      "learning_rate": 0.0005131578947368421,
      "loss": 0.4243,
      "step": 2590
    },
    {
      "epoch": 9.774436090225564,
      "grad_norm": 1.3232736587524414,
      "learning_rate": 0.0005112781954887218,
      "loss": 0.3997,
      "step": 2600
    },
    {
      "epoch": 9.81203007518797,
      "grad_norm": 0.8226320147514343,
      "learning_rate": 0.0005093984962406016,
      "loss": 0.3989,
      "step": 2610
    },
    {
      "epoch": 9.849624060150376,
      "grad_norm": 1.3629651069641113,
      "learning_rate": 0.0005075187969924812,
      "loss": 0.397,
      "step": 2620
    },
    {
      "epoch": 9.887218045112782,
      "grad_norm": 0.6528108716011047,
      "learning_rate": 0.0005056390977443609,
      "loss": 0.3875,
      "step": 2630
    },
    {
      "epoch": 9.924812030075188,
      "grad_norm": 1.2534379959106445,
      "learning_rate": 0.0005037593984962407,
      "loss": 0.4272,
      "step": 2640
    },
    {
      "epoch": 9.962406015037594,
      "grad_norm": 1.9562768936157227,
      "learning_rate": 0.0005018796992481202,
      "loss": 0.3829,
      "step": 2650
    },
    {
      "epoch": 10.0,
      "grad_norm": 4.950033187866211,
      "learning_rate": 0.0005,
      "loss": 0.381,
      "step": 2660
    },
    {
      "epoch": 10.0,
      "eval_accuracy": 0.841,
      "eval_loss": 0.3668789565563202,
      "eval_runtime": 22.086,
      "eval_samples_per_second": 135.833,
      "eval_steps_per_second": 8.512,
      "step": 2660
    },
    {
      "epoch": 10.037593984962406,
      "grad_norm": 1.3044512271881104,
      "learning_rate": 0.0004981203007518797,
      "loss": 0.3464,
      "step": 2670
    },
    {
      "epoch": 10.075187969924812,
      "grad_norm": 2.0700387954711914,
      "learning_rate": 0.0004962406015037594,
      "loss": 0.3593,
      "step": 2680
    },
    {
      "epoch": 10.112781954887218,
      "grad_norm": 1.2640228271484375,
      "learning_rate": 0.0004943609022556391,
      "loss": 0.3787,
      "step": 2690
    },
    {
      "epoch": 10.150375939849624,
      "grad_norm": 2.790936231613159,
      "learning_rate": 0.0004924812030075188,
      "loss": 0.4535,
      "step": 2700
    },
    {
      "epoch": 10.18796992481203,
      "grad_norm": 0.9573176503181458,
      "learning_rate": 0.0004906015037593985,
      "loss": 0.3745,
      "step": 2710
    },
    {
      "epoch": 10.225563909774436,
      "grad_norm": 2.5296459197998047,
      "learning_rate": 0.0004887218045112781,
      "loss": 0.3602,
      "step": 2720
    },
    {
      "epoch": 10.263157894736842,
      "grad_norm": 0.6671951413154602,
      "learning_rate": 0.0004868421052631579,
      "loss": 0.3582,
      "step": 2730
    },
    {
      "epoch": 10.300751879699249,
      "grad_norm": 0.8192895650863647,
      "learning_rate": 0.0004849624060150376,
      "loss": 0.3888,
      "step": 2740
    },
    {
      "epoch": 10.338345864661655,
      "grad_norm": 1.6077497005462646,
      "learning_rate": 0.0004830827067669173,
      "loss": 0.3869,
      "step": 2750
    },
    {
      "epoch": 10.37593984962406,
      "grad_norm": 1.5548243522644043,
      "learning_rate": 0.000481203007518797,
      "loss": 0.4189,
      "step": 2760
    },
    {
      "epoch": 10.413533834586467,
      "grad_norm": 3.113053798675537,
      "learning_rate": 0.0004793233082706767,
      "loss": 0.4125,
      "step": 2770
    },
    {
      "epoch": 10.451127819548873,
      "grad_norm": 1.9541460275650024,
      "learning_rate": 0.00047744360902255643,
      "loss": 0.3732,
      "step": 2780
    },
    {
      "epoch": 10.488721804511279,
      "grad_norm": 0.8041659593582153,
      "learning_rate": 0.0004755639097744361,
      "loss": 0.4011,
      "step": 2790
    },
    {
      "epoch": 10.526315789473685,
      "grad_norm": 2.1168713569641113,
      "learning_rate": 0.00047368421052631577,
      "loss": 0.4178,
      "step": 2800
    },
    {
      "epoch": 10.563909774436091,
      "grad_norm": 0.9540238380432129,
      "learning_rate": 0.0004718045112781955,
      "loss": 0.4402,
      "step": 2810
    },
    {
      "epoch": 10.601503759398497,
      "grad_norm": 1.7291501760482788,
      "learning_rate": 0.0004699248120300752,
      "loss": 0.3488,
      "step": 2820
    },
    {
      "epoch": 10.639097744360903,
      "grad_norm": 2.9654853343963623,
      "learning_rate": 0.0004680451127819549,
      "loss": 0.4044,
      "step": 2830
    },
    {
      "epoch": 10.676691729323307,
      "grad_norm": 1.4249536991119385,
      "learning_rate": 0.00046616541353383456,
      "loss": 0.3418,
      "step": 2840
    },
    {
      "epoch": 10.714285714285714,
      "grad_norm": 1.3514124155044556,
      "learning_rate": 0.00046428571428571433,
      "loss": 0.422,
      "step": 2850
    },
    {
      "epoch": 10.75187969924812,
      "grad_norm": 1.7847254276275635,
      "learning_rate": 0.000462406015037594,
      "loss": 0.3824,
      "step": 2860
    },
    {
      "epoch": 10.789473684210526,
      "grad_norm": 0.8014209866523743,
      "learning_rate": 0.0004605263157894737,
      "loss": 0.4106,
      "step": 2870
    },
    {
      "epoch": 10.827067669172932,
      "grad_norm": 2.8425509929656982,
      "learning_rate": 0.00045864661654135334,
      "loss": 0.4206,
      "step": 2880
    },
    {
      "epoch": 10.864661654135338,
      "grad_norm": 3.328763723373413,
      "learning_rate": 0.0004567669172932331,
      "loss": 0.4112,
      "step": 2890
    },
    {
      "epoch": 10.902255639097744,
      "grad_norm": 0.8171393871307373,
      "learning_rate": 0.0004548872180451128,
      "loss": 0.3577,
      "step": 2900
    },
    {
      "epoch": 10.93984962406015,
      "grad_norm": 1.702046513557434,
      "learning_rate": 0.00045300751879699246,
      "loss": 0.4005,
      "step": 2910
    },
    {
      "epoch": 10.977443609022556,
      "grad_norm": 2.0510404109954834,
      "learning_rate": 0.0004511278195488722,
      "loss": 0.3683,
      "step": 2920
    },
    {
      "epoch": 11.0,
      "eval_accuracy": 0.8343333333333334,
      "eval_loss": 0.37260717153549194,
      "eval_runtime": 22.3616,
      "eval_samples_per_second": 134.159,
      "eval_steps_per_second": 8.407,
      "step": 2926
    },
    {
      "epoch": 11.015037593984962,
      "grad_norm": 1.4914222955703735,
      "learning_rate": 0.0004492481203007519,
      "loss": 0.3892,
      "step": 2930
    },
    {
      "epoch": 11.052631578947368,
      "grad_norm": 1.2797698974609375,
      "learning_rate": 0.0004473684210526316,
      "loss": 0.4017,
      "step": 2940
    },
    {
      "epoch": 11.090225563909774,
      "grad_norm": 1.3382501602172852,
      "learning_rate": 0.00044548872180451125,
      "loss": 0.3662,
      "step": 2950
    },
    {
      "epoch": 11.12781954887218,
      "grad_norm": 1.1796543598175049,
      "learning_rate": 0.000443609022556391,
      "loss": 0.4037,
      "step": 2960
    },
    {
      "epoch": 11.165413533834586,
      "grad_norm": 2.0552074909210205,
      "learning_rate": 0.0004417293233082707,
      "loss": 0.3799,
      "step": 2970
    },
    {
      "epoch": 11.203007518796992,
      "grad_norm": 1.9363837242126465,
      "learning_rate": 0.00043984962406015037,
      "loss": 0.3992,
      "step": 2980
    },
    {
      "epoch": 11.240601503759398,
      "grad_norm": 2.565416097640991,
      "learning_rate": 0.0004379699248120301,
      "loss": 0.4213,
      "step": 2990
    },
    {
      "epoch": 11.278195488721805,
      "grad_norm": 1.1537913084030151,
      "learning_rate": 0.00043609022556390976,
      "loss": 0.367,
      "step": 3000
    },
    {
      "epoch": 11.31578947368421,
      "grad_norm": 0.9546396136283875,
      "learning_rate": 0.0004342105263157895,
      "loss": 0.3177,
      "step": 3010
    },
    {
      "epoch": 11.353383458646617,
      "grad_norm": 1.6177332401275635,
      "learning_rate": 0.0004323308270676692,
      "loss": 0.4099,
      "step": 3020
    },
    {
      "epoch": 11.390977443609023,
      "grad_norm": 1.7691994905471802,
      "learning_rate": 0.0004304511278195489,
      "loss": 0.4099,
      "step": 3030
    },
    {
      "epoch": 11.428571428571429,
      "grad_norm": 2.3439950942993164,
      "learning_rate": 0.00042857142857142855,
      "loss": 0.4062,
      "step": 3040
    },
    {
      "epoch": 11.466165413533835,
      "grad_norm": 1.2884137630462646,
      "learning_rate": 0.0004266917293233083,
      "loss": 0.4165,
      "step": 3050
    },
    {
      "epoch": 11.503759398496241,
      "grad_norm": 3.1185688972473145,
      "learning_rate": 0.000424812030075188,
      "loss": 0.3755,
      "step": 3060
    },
    {
      "epoch": 11.541353383458647,
      "grad_norm": 1.4371860027313232,
      "learning_rate": 0.00042293233082706767,
      "loss": 0.4106,
      "step": 3070
    },
    {
      "epoch": 11.578947368421053,
      "grad_norm": 2.0837807655334473,
      "learning_rate": 0.00042105263157894734,
      "loss": 0.397,
      "step": 3080
    },
    {
      "epoch": 11.61654135338346,
      "grad_norm": 0.7074570059776306,
      "learning_rate": 0.0004191729323308271,
      "loss": 0.4158,
      "step": 3090
    },
    {
      "epoch": 11.654135338345865,
      "grad_norm": 1.1207952499389648,
      "learning_rate": 0.0004172932330827068,
      "loss": 0.3961,
      "step": 3100
    },
    {
      "epoch": 11.691729323308271,
      "grad_norm": 1.644635558128357,
      "learning_rate": 0.00041541353383458646,
      "loss": 0.411,
      "step": 3110
    },
    {
      "epoch": 11.729323308270677,
      "grad_norm": 0.8449338674545288,
      "learning_rate": 0.0004135338345864661,
      "loss": 0.3516,
      "step": 3120
    },
    {
      "epoch": 11.766917293233083,
      "grad_norm": 1.1057316064834595,
      "learning_rate": 0.0004116541353383459,
      "loss": 0.364,
      "step": 3130
    },
    {
      "epoch": 11.80451127819549,
      "grad_norm": 1.7223906517028809,
      "learning_rate": 0.0004097744360902256,
      "loss": 0.3867,
      "step": 3140
    },
    {
      "epoch": 11.842105263157894,
      "grad_norm": 1.929753065109253,
      "learning_rate": 0.00040789473684210524,
      "loss": 0.3854,
      "step": 3150
    },
    {
      "epoch": 11.8796992481203,
      "grad_norm": 3.2198550701141357,
      "learning_rate": 0.00040601503759398497,
      "loss": 0.3678,
      "step": 3160
    },
    {
      "epoch": 11.917293233082706,
      "grad_norm": 3.1026694774627686,
      "learning_rate": 0.0004041353383458647,
      "loss": 0.3448,
      "step": 3170
    },
    {
      "epoch": 11.954887218045112,
      "grad_norm": 3.580455780029297,
      "learning_rate": 0.00040225563909774436,
      "loss": 0.3446,
      "step": 3180
    },
    {
      "epoch": 11.992481203007518,
      "grad_norm": 1.192884922027588,
      "learning_rate": 0.0004003759398496241,
      "loss": 0.4106,
      "step": 3190
    },
    {
      "epoch": 12.0,
      "eval_accuracy": 0.8306666666666667,
      "eval_loss": 0.3742680251598358,
      "eval_runtime": 23.3506,
      "eval_samples_per_second": 128.476,
      "eval_steps_per_second": 8.051,
      "step": 3192
    },
    {
      "epoch": 12.030075187969924,
      "grad_norm": 0.6555389761924744,
      "learning_rate": 0.00039849624060150376,
      "loss": 0.4158,
      "step": 3200
    },
    {
      "epoch": 12.06766917293233,
      "grad_norm": 2.0689053535461426,
      "learning_rate": 0.0003966165413533835,
      "loss": 0.3433,
      "step": 3210
    },
    {
      "epoch": 12.105263157894736,
      "grad_norm": 2.667926788330078,
      "learning_rate": 0.00039473684210526315,
      "loss": 0.3803,
      "step": 3220
    },
    {
      "epoch": 12.142857142857142,
      "grad_norm": 1.3686374425888062,
      "learning_rate": 0.0003928571428571429,
      "loss": 0.4179,
      "step": 3230
    },
    {
      "epoch": 12.180451127819548,
      "grad_norm": 1.6463954448699951,
      "learning_rate": 0.00039097744360902254,
      "loss": 0.3756,
      "step": 3240
    },
    {
      "epoch": 12.218045112781954,
      "grad_norm": 1.8780977725982666,
      "learning_rate": 0.00038909774436090227,
      "loss": 0.3709,
      "step": 3250
    },
    {
      "epoch": 12.25563909774436,
      "grad_norm": 2.3425662517547607,
      "learning_rate": 0.000387218045112782,
      "loss": 0.3954,
      "step": 3260
    },
    {
      "epoch": 12.293233082706767,
      "grad_norm": 1.2193098068237305,
      "learning_rate": 0.00038533834586466166,
      "loss": 0.4205,
      "step": 3270
    },
    {
      "epoch": 12.330827067669173,
      "grad_norm": 1.0558803081512451,
      "learning_rate": 0.00038345864661654133,
      "loss": 0.4196,
      "step": 3280
    },
    {
      "epoch": 12.368421052631579,
      "grad_norm": 0.8328695893287659,
      "learning_rate": 0.00038157894736842105,
      "loss": 0.3708,
      "step": 3290
    },
    {
      "epoch": 12.406015037593985,
      "grad_norm": 1.3041069507598877,
      "learning_rate": 0.0003796992481203008,
      "loss": 0.3892,
      "step": 3300
    },
    {
      "epoch": 12.443609022556391,
      "grad_norm": 1.636218547821045,
      "learning_rate": 0.00037781954887218045,
      "loss": 0.3647,
      "step": 3310
    },
    {
      "epoch": 12.481203007518797,
      "grad_norm": 3.1060903072357178,
      "learning_rate": 0.0003759398496240601,
      "loss": 0.3656,
      "step": 3320
    },
    {
      "epoch": 12.518796992481203,
      "grad_norm": 2.0514092445373535,
      "learning_rate": 0.0003740601503759399,
      "loss": 0.3722,
      "step": 3330
    },
    {
      "epoch": 12.556390977443609,
      "grad_norm": 1.0699191093444824,
      "learning_rate": 0.00037218045112781957,
      "loss": 0.414,
      "step": 3340
    },
    {
      "epoch": 12.593984962406015,
      "grad_norm": 2.301192283630371,
      "learning_rate": 0.00037030075187969924,
      "loss": 0.397,
      "step": 3350
    },
    {
      "epoch": 12.631578947368421,
      "grad_norm": 1.7151697874069214,
      "learning_rate": 0.00036842105263157896,
      "loss": 0.4197,
      "step": 3360
    },
    {
      "epoch": 12.669172932330827,
      "grad_norm": 1.8056873083114624,
      "learning_rate": 0.0003665413533834587,
      "loss": 0.452,
      "step": 3370
    },
    {
      "epoch": 12.706766917293233,
      "grad_norm": 2.7183663845062256,
      "learning_rate": 0.00036466165413533835,
      "loss": 0.3697,
      "step": 3380
    },
    {
      "epoch": 12.74436090225564,
      "grad_norm": 1.620190143585205,
      "learning_rate": 0.000362781954887218,
      "loss": 0.3468,
      "step": 3390
    },
    {
      "epoch": 12.781954887218046,
      "grad_norm": 1.0759128332138062,
      "learning_rate": 0.00036090225563909775,
      "loss": 0.3884,
      "step": 3400
    },
    {
      "epoch": 12.819548872180452,
      "grad_norm": 2.260793924331665,
      "learning_rate": 0.00035902255639097747,
      "loss": 0.4402,
      "step": 3410
    },
    {
      "epoch": 12.857142857142858,
      "grad_norm": 2.547682046890259,
      "learning_rate": 0.00035714285714285714,
      "loss": 0.3987,
      "step": 3420
    },
    {
      "epoch": 12.894736842105264,
      "grad_norm": 2.1432294845581055,
      "learning_rate": 0.00035526315789473687,
      "loss": 0.4033,
      "step": 3430
    },
    {
      "epoch": 12.93233082706767,
      "grad_norm": 1.1086194515228271,
      "learning_rate": 0.00035338345864661654,
      "loss": 0.3922,
      "step": 3440
    },
    {
      "epoch": 12.969924812030076,
      "grad_norm": 1.5204222202301025,
      "learning_rate": 0.00035150375939849626,
      "loss": 0.3801,
      "step": 3450
    },
    {
      "epoch": 13.0,
      "eval_accuracy": 0.8353333333333334,
      "eval_loss": 0.3932444751262665,
      "eval_runtime": 23.3775,
      "eval_samples_per_second": 128.329,
      "eval_steps_per_second": 8.042,
      "step": 3458
    },
    {
      "epoch": 13.007518796992482,
      "grad_norm": 0.7549734711647034,
      "learning_rate": 0.00034962406015037593,
      "loss": 0.3233,
      "step": 3460
    },
    {
      "epoch": 13.045112781954888,
      "grad_norm": 1.4083014726638794,
      "learning_rate": 0.00034774436090225565,
      "loss": 0.3449,
      "step": 3470
    },
    {
      "epoch": 13.082706766917294,
      "grad_norm": 1.439350962638855,
      "learning_rate": 0.0003458646616541353,
      "loss": 0.3819,
      "step": 3480
    },
    {
      "epoch": 13.1203007518797,
      "grad_norm": 2.3085172176361084,
      "learning_rate": 0.00034398496240601505,
      "loss": 0.384,
      "step": 3490
    },
    {
      "epoch": 13.157894736842104,
      "grad_norm": 3.2713489532470703,
      "learning_rate": 0.00034210526315789477,
      "loss": 0.3973,
      "step": 3500
    },
    {
      "epoch": 13.19548872180451,
      "grad_norm": 1.2386587858200073,
      "learning_rate": 0.00034022556390977444,
      "loss": 0.3891,
      "step": 3510
    },
    {
      "epoch": 13.233082706766917,
      "grad_norm": 2.399829626083374,
      "learning_rate": 0.0003383458646616541,
      "loss": 0.3996,
      "step": 3520
    },
    {
      "epoch": 13.270676691729323,
      "grad_norm": 2.8388304710388184,
      "learning_rate": 0.0003364661654135339,
      "loss": 0.3953,
      "step": 3530
    },
    {
      "epoch": 13.308270676691729,
      "grad_norm": 1.1046913862228394,
      "learning_rate": 0.00033458646616541356,
      "loss": 0.3268,
      "step": 3540
    },
    {
      "epoch": 13.345864661654135,
      "grad_norm": 1.8203587532043457,
      "learning_rate": 0.00033270676691729323,
      "loss": 0.3729,
      "step": 3550
    },
    {
      "epoch": 13.38345864661654,
      "grad_norm": 1.1816965341567993,
      "learning_rate": 0.0003308270676691729,
      "loss": 0.3406,
      "step": 3560
    },
    {
      "epoch": 13.421052631578947,
      "grad_norm": 1.5740747451782227,
      "learning_rate": 0.0003289473684210527,
      "loss": 0.3145,
      "step": 3570
    },
    {
      "epoch": 13.458646616541353,
      "grad_norm": 1.018089771270752,
      "learning_rate": 0.00032706766917293235,
      "loss": 0.3282,
      "step": 3580
    },
    {
      "epoch": 13.496240601503759,
      "grad_norm": 0.8377684950828552,
      "learning_rate": 0.000325187969924812,
      "loss": 0.3231,
      "step": 3590
    },
    {
      "epoch": 13.533834586466165,
      "grad_norm": 1.2480101585388184,
      "learning_rate": 0.00032330827067669174,
      "loss": 0.3801,
      "step": 3600
    },
    {
      "epoch": 13.571428571428571,
      "grad_norm": 1.5848987102508545,
      "learning_rate": 0.00032142857142857147,
      "loss": 0.3173,
      "step": 3610
    },
    {
      "epoch": 13.609022556390977,
      "grad_norm": 2.7975924015045166,
      "learning_rate": 0.00031954887218045114,
      "loss": 0.3612,
      "step": 3620
    },
    {
      "epoch": 13.646616541353383,
      "grad_norm": 1.3311034440994263,
      "learning_rate": 0.0003176691729323308,
      "loss": 0.3397,
      "step": 3630
    },
    {
      "epoch": 13.68421052631579,
      "grad_norm": 1.7701468467712402,
      "learning_rate": 0.00031578947368421053,
      "loss": 0.3466,
      "step": 3640
    },
    {
      "epoch": 13.721804511278195,
      "grad_norm": 1.4932445287704468,
      "learning_rate": 0.00031390977443609025,
      "loss": 0.3911,
      "step": 3650
    },
    {
      "epoch": 13.759398496240602,
      "grad_norm": 1.1234118938446045,
      "learning_rate": 0.0003120300751879699,
      "loss": 0.3708,
      "step": 3660
    },
    {
      "epoch": 13.796992481203008,
      "grad_norm": 3.132136344909668,
      "learning_rate": 0.00031015037593984965,
      "loss": 0.3591,
      "step": 3670
    },
    {
      "epoch": 13.834586466165414,
      "grad_norm": 0.9284883737564087,
      "learning_rate": 0.0003082706766917293,
      "loss": 0.3603,
      "step": 3680
    },
    {
      "epoch": 13.87218045112782,
      "grad_norm": 2.743607997894287,
      "learning_rate": 0.00030639097744360904,
      "loss": 0.3692,
      "step": 3690
    },
    {
      "epoch": 13.909774436090226,
      "grad_norm": 0.9718323945999146,
      "learning_rate": 0.00030451127819548877,
      "loss": 0.3425,
      "step": 3700
    },
    {
      "epoch": 13.947368421052632,
      "grad_norm": 3.698681354522705,
      "learning_rate": 0.00030263157894736844,
      "loss": 0.4044,
      "step": 3710
    },
    {
      "epoch": 13.984962406015038,
      "grad_norm": 1.169474720954895,
      "learning_rate": 0.0003007518796992481,
      "loss": 0.3618,
      "step": 3720
    },
    {
      "epoch": 14.0,
      "eval_accuracy": 0.828,
      "eval_loss": 0.38493749499320984,
      "eval_runtime": 22.4459,
      "eval_samples_per_second": 133.655,
      "eval_steps_per_second": 8.376,
      "step": 3724
    },
    {
      "epoch": 14.022556390977444,
      "grad_norm": 1.5844948291778564,
      "learning_rate": 0.00029887218045112783,
      "loss": 0.368,
      "step": 3730
    },
    {
      "epoch": 14.06015037593985,
      "grad_norm": 0.718728244304657,
      "learning_rate": 0.00029699248120300755,
      "loss": 0.363,
      "step": 3740
    },
    {
      "epoch": 14.097744360902256,
      "grad_norm": 2.2383339405059814,
      "learning_rate": 0.0002951127819548872,
      "loss": 0.367,
      "step": 3750
    },
    {
      "epoch": 14.135338345864662,
      "grad_norm": 0.7776492238044739,
      "learning_rate": 0.0002932330827067669,
      "loss": 0.3507,
      "step": 3760
    },
    {
      "epoch": 14.172932330827068,
      "grad_norm": 1.9525710344314575,
      "learning_rate": 0.00029135338345864667,
      "loss": 0.3544,
      "step": 3770
    },
    {
      "epoch": 14.210526315789474,
      "grad_norm": 1.6315656900405884,
      "learning_rate": 0.00028947368421052634,
      "loss": 0.3817,
      "step": 3780
    },
    {
      "epoch": 14.24812030075188,
      "grad_norm": 2.3311429023742676,
      "learning_rate": 0.000287593984962406,
      "loss": 0.406,
      "step": 3790
    },
    {
      "epoch": 14.285714285714286,
      "grad_norm": 0.7054960131645203,
      "learning_rate": 0.0002857142857142857,
      "loss": 0.364,
      "step": 3800
    },
    {
      "epoch": 14.323308270676693,
      "grad_norm": 2.173898458480835,
      "learning_rate": 0.00028383458646616546,
      "loss": 0.3801,
      "step": 3810
    },
    {
      "epoch": 14.360902255639097,
      "grad_norm": 1.2254208326339722,
      "learning_rate": 0.00028195488721804513,
      "loss": 0.3247,
      "step": 3820
    },
    {
      "epoch": 14.398496240601503,
      "grad_norm": 2.001476526260376,
      "learning_rate": 0.0002800751879699248,
      "loss": 0.3572,
      "step": 3830
    },
    {
      "epoch": 14.436090225563909,
      "grad_norm": 1.5986863374710083,
      "learning_rate": 0.0002781954887218045,
      "loss": 0.3404,
      "step": 3840
    },
    {
      "epoch": 14.473684210526315,
      "grad_norm": 2.656485080718994,
      "learning_rate": 0.00027631578947368425,
      "loss": 0.3045,
      "step": 3850
    },
    {
      "epoch": 14.511278195488721,
      "grad_norm": 1.2519398927688599,
      "learning_rate": 0.0002744360902255639,
      "loss": 0.3403,
      "step": 3860
    },
    {
      "epoch": 14.548872180451127,
      "grad_norm": 2.0121729373931885,
      "learning_rate": 0.0002725563909774436,
      "loss": 0.3835,
      "step": 3870
    },
    {
      "epoch": 14.586466165413533,
      "grad_norm": 2.51650333404541,
      "learning_rate": 0.0002706766917293233,
      "loss": 0.43,
      "step": 3880
    },
    {
      "epoch": 14.62406015037594,
      "grad_norm": 0.7833250761032104,
      "learning_rate": 0.00026879699248120304,
      "loss": 0.3143,
      "step": 3890
    },
    {
      "epoch": 14.661654135338345,
      "grad_norm": 3.44852614402771,
      "learning_rate": 0.0002669172932330827,
      "loss": 0.333,
      "step": 3900
    },
    {
      "epoch": 14.699248120300751,
      "grad_norm": 1.6635687351226807,
      "learning_rate": 0.00026503759398496243,
      "loss": 0.3509,
      "step": 3910
    },
    {
      "epoch": 14.736842105263158,
      "grad_norm": 1.0032105445861816,
      "learning_rate": 0.0002631578947368421,
      "loss": 0.3339,
      "step": 3920
    },
    {
      "epoch": 14.774436090225564,
      "grad_norm": 2.4193527698516846,
      "learning_rate": 0.0002612781954887218,
      "loss": 0.3852,
      "step": 3930
    },
    {
      "epoch": 14.81203007518797,
      "grad_norm": 1.3810863494873047,
      "learning_rate": 0.00025939849624060155,
      "loss": 0.3302,
      "step": 3940
    },
    {
      "epoch": 14.849624060150376,
      "grad_norm": 1.8141798973083496,
      "learning_rate": 0.0002575187969924812,
      "loss": 0.343,
      "step": 3950
    },
    {
      "epoch": 14.887218045112782,
      "grad_norm": 0.9076376557350159,
      "learning_rate": 0.0002556390977443609,
      "loss": 0.3158,
      "step": 3960
    },
    {
      "epoch": 14.924812030075188,
      "grad_norm": 1.8109593391418457,
      "learning_rate": 0.0002537593984962406,
      "loss": 0.3157,
      "step": 3970
    },
    {
      "epoch": 14.962406015037594,
      "grad_norm": 4.671741008758545,
      "learning_rate": 0.00025187969924812034,
      "loss": 0.3563,
      "step": 3980
    },
    {
      "epoch": 15.0,
      "grad_norm": 1.3449598550796509,
      "learning_rate": 0.00025,
      "loss": 0.3616,
      "step": 3990
    },
    {
      "epoch": 15.0,
      "eval_accuracy": 0.8363333333333334,
      "eval_loss": 0.3611679673194885,
      "eval_runtime": 22.6124,
      "eval_samples_per_second": 132.67,
      "eval_steps_per_second": 8.314,
      "step": 3990
    },
    {
      "epoch": 15.037593984962406,
      "grad_norm": 1.0720893144607544,
      "learning_rate": 0.0002481203007518797,
      "loss": 0.3766,
      "step": 4000
    },
    {
      "epoch": 15.075187969924812,
      "grad_norm": 1.4466170072555542,
      "learning_rate": 0.0002462406015037594,
      "loss": 0.3216,
      "step": 4010
    },
    {
      "epoch": 15.112781954887218,
      "grad_norm": 2.477530002593994,
      "learning_rate": 0.00024436090225563907,
      "loss": 0.3281,
      "step": 4020
    },
    {
      "epoch": 15.150375939849624,
      "grad_norm": 2.987055778503418,
      "learning_rate": 0.0002424812030075188,
      "loss": 0.3679,
      "step": 4030
    },
    {
      "epoch": 15.18796992481203,
      "grad_norm": 3.0904104709625244,
      "learning_rate": 0.0002406015037593985,
      "loss": 0.3455,
      "step": 4040
    },
    {
      "epoch": 15.225563909774436,
      "grad_norm": 1.6026345491409302,
      "learning_rate": 0.00023872180451127821,
      "loss": 0.3368,
      "step": 4050
    },
    {
      "epoch": 15.263157894736842,
      "grad_norm": 1.7488104104995728,
      "learning_rate": 0.00023684210526315788,
      "loss": 0.3248,
      "step": 4060
    },
    {
      "epoch": 15.300751879699249,
      "grad_norm": 1.3201777935028076,
      "learning_rate": 0.0002349624060150376,
      "loss": 0.3384,
      "step": 4070
    },
    {
      "epoch": 15.338345864661655,
      "grad_norm": 2.0366835594177246,
      "learning_rate": 0.00023308270676691728,
      "loss": 0.3647,
      "step": 4080
    },
    {
      "epoch": 15.37593984962406,
      "grad_norm": 3.556360960006714,
      "learning_rate": 0.000231203007518797,
      "loss": 0.3655,
      "step": 4090
    },
    {
      "epoch": 15.413533834586467,
      "grad_norm": 1.0696372985839844,
      "learning_rate": 0.00022932330827067667,
      "loss": 0.3901,
      "step": 4100
    },
    {
      "epoch": 15.451127819548873,
      "grad_norm": 1.5107637643814087,
      "learning_rate": 0.0002274436090225564,
      "loss": 0.3885,
      "step": 4110
    },
    {
      "epoch": 15.488721804511279,
      "grad_norm": 0.8477464914321899,
      "learning_rate": 0.0002255639097744361,
      "loss": 0.3412,
      "step": 4120
    },
    {
      "epoch": 15.526315789473685,
      "grad_norm": 1.057342767715454,
      "learning_rate": 0.0002236842105263158,
      "loss": 0.3064,
      "step": 4130
    },
    {
      "epoch": 15.563909774436091,
      "grad_norm": 1.8280675411224365,
      "learning_rate": 0.0002218045112781955,
      "loss": 0.3422,
      "step": 4140
    },
    {
      "epoch": 15.601503759398497,
      "grad_norm": 1.8485440015792847,
      "learning_rate": 0.00021992481203007518,
      "loss": 0.3253,
      "step": 4150
    },
    {
      "epoch": 15.639097744360903,
      "grad_norm": 0.9240747094154358,
      "learning_rate": 0.00021804511278195488,
      "loss": 0.2992,
      "step": 4160
    },
    {
      "epoch": 15.676691729323307,
      "grad_norm": 2.0516128540039062,
      "learning_rate": 0.0002161654135338346,
      "loss": 0.3188,
      "step": 4170
    },
    {
      "epoch": 15.714285714285714,
      "grad_norm": 1.8810023069381714,
      "learning_rate": 0.00021428571428571427,
      "loss": 0.3617,
      "step": 4180
    },
    {
      "epoch": 15.75187969924812,
      "grad_norm": 2.1912035942077637,
      "learning_rate": 0.000212406015037594,
      "loss": 0.3072,
      "step": 4190
    },
    {
      "epoch": 15.789473684210526,
      "grad_norm": 1.955126404762268,
      "learning_rate": 0.00021052631578947367,
      "loss": 0.3506,
      "step": 4200
    },
    {
      "epoch": 15.827067669172932,
      "grad_norm": 1.2552382946014404,
      "learning_rate": 0.0002086466165413534,
      "loss": 0.3644,
      "step": 4210
    },
    {
      "epoch": 15.864661654135338,
      "grad_norm": 1.733071208000183,
      "learning_rate": 0.00020676691729323306,
      "loss": 0.3582,
      "step": 4220
    },
    {
      "epoch": 15.902255639097744,
      "grad_norm": 2.950096368789673,
      "learning_rate": 0.0002048872180451128,
      "loss": 0.3575,
      "step": 4230
    },
    {
      "epoch": 15.93984962406015,
      "grad_norm": 0.7415263652801514,
      "learning_rate": 0.00020300751879699248,
      "loss": 0.3515,
      "step": 4240
    },
    {
      "epoch": 15.977443609022556,
      "grad_norm": 2.2890806198120117,
      "learning_rate": 0.00020112781954887218,
      "loss": 0.3598,
      "step": 4250
    },
    {
      "epoch": 16.0,
      "eval_accuracy": 0.84,
      "eval_loss": 0.3545418679714203,
      "eval_runtime": 22.4454,
      "eval_samples_per_second": 133.658,
      "eval_steps_per_second": 8.376,
      "step": 4256
    },
    {
      "epoch": 16.015037593984964,
      "grad_norm": 1.4989255666732788,
      "learning_rate": 0.00019924812030075188,
      "loss": 0.3485,
      "step": 4260
    },
    {
      "epoch": 16.05263157894737,
      "grad_norm": 1.4415109157562256,
      "learning_rate": 0.00019736842105263157,
      "loss": 0.3221,
      "step": 4270
    },
    {
      "epoch": 16.090225563909776,
      "grad_norm": 1.4951825141906738,
      "learning_rate": 0.00019548872180451127,
      "loss": 0.3357,
      "step": 4280
    },
    {
      "epoch": 16.127819548872182,
      "grad_norm": 1.8720006942749023,
      "learning_rate": 0.000193609022556391,
      "loss": 0.3463,
      "step": 4290
    },
    {
      "epoch": 16.165413533834588,
      "grad_norm": 1.7324212789535522,
      "learning_rate": 0.00019172932330827067,
      "loss": 0.3775,
      "step": 4300
    },
    {
      "epoch": 16.203007518796994,
      "grad_norm": 2.557533025741577,
      "learning_rate": 0.0001898496240601504,
      "loss": 0.3434,
      "step": 4310
    },
    {
      "epoch": 16.2406015037594,
      "grad_norm": 3.1829793453216553,
      "learning_rate": 0.00018796992481203006,
      "loss": 0.3168,
      "step": 4320
    },
    {
      "epoch": 16.278195488721803,
      "grad_norm": 5.803896903991699,
      "learning_rate": 0.00018609022556390978,
      "loss": 0.3333,
      "step": 4330
    },
    {
      "epoch": 16.31578947368421,
      "grad_norm": 1.1681098937988281,
      "learning_rate": 0.00018421052631578948,
      "loss": 0.3338,
      "step": 4340
    },
    {
      "epoch": 16.353383458646615,
      "grad_norm": 0.8097240328788757,
      "learning_rate": 0.00018233082706766918,
      "loss": 0.3294,
      "step": 4350
    },
    {
      "epoch": 16.39097744360902,
      "grad_norm": 1.8691591024398804,
      "learning_rate": 0.00018045112781954887,
      "loss": 0.3723,
      "step": 4360
    },
    {
      "epoch": 16.428571428571427,
      "grad_norm": 1.2510162591934204,
      "learning_rate": 0.00017857142857142857,
      "loss": 0.3524,
      "step": 4370
    },
    {
      "epoch": 16.466165413533833,
      "grad_norm": 1.7406212091445923,
      "learning_rate": 0.00017669172932330827,
      "loss": 0.3432,
      "step": 4380
    },
    {
      "epoch": 16.50375939849624,
      "grad_norm": 0.9350534677505493,
      "learning_rate": 0.00017481203007518797,
      "loss": 0.3101,
      "step": 4390
    },
    {
      "epoch": 16.541353383458645,
      "grad_norm": 0.5712730288505554,
      "learning_rate": 0.00017293233082706766,
      "loss": 0.3436,
      "step": 4400
    },
    {
      "epoch": 16.57894736842105,
      "grad_norm": 1.3796412944793701,
      "learning_rate": 0.00017105263157894739,
      "loss": 0.3022,
      "step": 4410
    },
    {
      "epoch": 16.616541353383457,
      "grad_norm": 1.43451726436615,
      "learning_rate": 0.00016917293233082706,
      "loss": 0.3323,
      "step": 4420
    },
    {
      "epoch": 16.654135338345863,
      "grad_norm": 1.5854177474975586,
      "learning_rate": 0.00016729323308270678,
      "loss": 0.3159,
      "step": 4430
    },
    {
      "epoch": 16.69172932330827,
      "grad_norm": 1.6263128519058228,
      "learning_rate": 0.00016541353383458645,
      "loss": 0.3869,
      "step": 4440
    },
    {
      "epoch": 16.729323308270676,
      "grad_norm": 3.4855844974517822,
      "learning_rate": 0.00016353383458646617,
      "loss": 0.309,
      "step": 4450
    },
    {
      "epoch": 16.76691729323308,
      "grad_norm": 1.9914530515670776,
      "learning_rate": 0.00016165413533834587,
      "loss": 0.3149,
      "step": 4460
    },
    {
      "epoch": 16.804511278195488,
      "grad_norm": 2.266146659851074,
      "learning_rate": 0.00015977443609022557,
      "loss": 0.347,
      "step": 4470
    },
    {
      "epoch": 16.842105263157894,
      "grad_norm": 0.9908347725868225,
      "learning_rate": 0.00015789473684210527,
      "loss": 0.3046,
      "step": 4480
    },
    {
      "epoch": 16.8796992481203,
      "grad_norm": 0.9130592346191406,
      "learning_rate": 0.00015601503759398496,
      "loss": 0.3134,
      "step": 4490
    },
    {
      "epoch": 16.917293233082706,
      "grad_norm": 1.7604531049728394,
      "learning_rate": 0.00015413533834586466,
      "loss": 0.2844,
      "step": 4500
    },
    {
      "epoch": 16.954887218045112,
      "grad_norm": 2.0662553310394287,
      "learning_rate": 0.00015225563909774438,
      "loss": 0.3481,
      "step": 4510
    },
    {
      "epoch": 16.992481203007518,
      "grad_norm": 1.892341136932373,
      "learning_rate": 0.00015037593984962405,
      "loss": 0.3527,
      "step": 4520
    },
    {
      "epoch": 17.0,
      "eval_accuracy": 0.8433333333333334,
      "eval_loss": 0.3494355380535126,
      "eval_runtime": 23.2894,
      "eval_samples_per_second": 128.814,
      "eval_steps_per_second": 8.072,
      "step": 4522
    },
    {
      "epoch": 17.030075187969924,
      "grad_norm": 1.4964615106582642,
      "learning_rate": 0.00014849624060150378,
      "loss": 0.34,
      "step": 4530
    },
    {
      "epoch": 17.06766917293233,
      "grad_norm": 5.154122352600098,
      "learning_rate": 0.00014661654135338345,
      "loss": 0.3263,
      "step": 4540
    },
    {
      "epoch": 17.105263157894736,
      "grad_norm": 1.070294737815857,
      "learning_rate": 0.00014473684210526317,
      "loss": 0.3362,
      "step": 4550
    },
    {
      "epoch": 17.142857142857142,
      "grad_norm": 2.361374855041504,
      "learning_rate": 0.00014285714285714284,
      "loss": 0.3076,
      "step": 4560
    },
    {
      "epoch": 17.18045112781955,
      "grad_norm": 1.543022632598877,
      "learning_rate": 0.00014097744360902256,
      "loss": 0.3256,
      "step": 4570
    },
    {
      "epoch": 17.218045112781954,
      "grad_norm": 2.11079740524292,
      "learning_rate": 0.00013909774436090226,
      "loss": 0.3227,
      "step": 4580
    },
    {
      "epoch": 17.25563909774436,
      "grad_norm": 0.6600978374481201,
      "learning_rate": 0.00013721804511278196,
      "loss": 0.3432,
      "step": 4590
    },
    {
      "epoch": 17.293233082706767,
      "grad_norm": 1.5763723850250244,
      "learning_rate": 0.00013533834586466166,
      "loss": 0.3189,
      "step": 4600
    },
    {
      "epoch": 17.330827067669173,
      "grad_norm": 0.9486016035079956,
      "learning_rate": 0.00013345864661654135,
      "loss": 0.3389,
      "step": 4610
    },
    {
      "epoch": 17.36842105263158,
      "grad_norm": 3.0943470001220703,
      "learning_rate": 0.00013157894736842105,
      "loss": 0.3699,
      "step": 4620
    },
    {
      "epoch": 17.406015037593985,
      "grad_norm": 1.2410303354263306,
      "learning_rate": 0.00012969924812030077,
      "loss": 0.3359,
      "step": 4630
    },
    {
      "epoch": 17.44360902255639,
      "grad_norm": 1.2402234077453613,
      "learning_rate": 0.00012781954887218044,
      "loss": 0.3438,
      "step": 4640
    },
    {
      "epoch": 17.481203007518797,
      "grad_norm": 1.6898046731948853,
      "learning_rate": 0.00012593984962406017,
      "loss": 0.3154,
      "step": 4650
    },
    {
      "epoch": 17.518796992481203,
      "grad_norm": 0.5240353941917419,
      "learning_rate": 0.00012406015037593984,
      "loss": 0.3456,
      "step": 4660
    },
    {
      "epoch": 17.55639097744361,
      "grad_norm": 1.2222387790679932,
      "learning_rate": 0.00012218045112781953,
      "loss": 0.3226,
      "step": 4670
    },
    {
      "epoch": 17.593984962406015,
      "grad_norm": 1.5085129737854004,
      "learning_rate": 0.00012030075187969925,
      "loss": 0.3572,
      "step": 4680
    },
    {
      "epoch": 17.63157894736842,
      "grad_norm": 1.925484538078308,
      "learning_rate": 0.00011842105263157894,
      "loss": 0.3114,
      "step": 4690
    },
    {
      "epoch": 17.669172932330827,
      "grad_norm": 2.0894110202789307,
      "learning_rate": 0.00011654135338345864,
      "loss": 0.3253,
      "step": 4700
    },
    {
      "epoch": 17.706766917293233,
      "grad_norm": 0.7595771551132202,
      "learning_rate": 0.00011466165413533834,
      "loss": 0.3194,
      "step": 4710
    },
    {
      "epoch": 17.74436090225564,
      "grad_norm": 1.2056400775909424,
      "learning_rate": 0.00011278195488721805,
      "loss": 0.334,
      "step": 4720
    },
    {
      "epoch": 17.781954887218046,
      "grad_norm": 1.6775317192077637,
      "learning_rate": 0.00011090225563909774,
      "loss": 0.3338,
      "step": 4730
    },
    {
      "epoch": 17.81954887218045,
      "grad_norm": 0.9467508792877197,
      "learning_rate": 0.00010902255639097744,
      "loss": 0.3062,
      "step": 4740
    },
    {
      "epoch": 17.857142857142858,
      "grad_norm": 0.8269784450531006,
      "learning_rate": 0.00010714285714285714,
      "loss": 0.2833,
      "step": 4750
    },
    {
      "epoch": 17.894736842105264,
      "grad_norm": 0.9722714424133301,
      "learning_rate": 0.00010526315789473683,
      "loss": 0.367,
      "step": 4760
    },
    {
      "epoch": 17.93233082706767,
      "grad_norm": 3.393881320953369,
      "learning_rate": 0.00010338345864661653,
      "loss": 0.352,
      "step": 4770
    },
    {
      "epoch": 17.969924812030076,
      "grad_norm": 0.4009822607040405,
      "learning_rate": 0.00010150375939849624,
      "loss": 0.299,
      "step": 4780
    },
    {
      "epoch": 18.0,
      "eval_accuracy": 0.857,
      "eval_loss": 0.3301770091056824,
      "eval_runtime": 22.5233,
      "eval_samples_per_second": 133.196,
      "eval_steps_per_second": 8.347,
      "step": 4788
    },
    {
      "epoch": 18.007518796992482,
      "grad_norm": 2.283374786376953,
      "learning_rate": 9.962406015037594e-05,
      "loss": 0.3524,
      "step": 4790
    },
    {
      "epoch": 18.045112781954888,
      "grad_norm": 2.2666139602661133,
      "learning_rate": 9.774436090225564e-05,
      "loss": 0.3639,
      "step": 4800
    },
    {
      "epoch": 18.082706766917294,
      "grad_norm": 2.269416332244873,
      "learning_rate": 9.586466165413533e-05,
      "loss": 0.3282,
      "step": 4810
    },
    {
      "epoch": 18.1203007518797,
      "grad_norm": 2.8119919300079346,
      "learning_rate": 9.398496240601503e-05,
      "loss": 0.355,
      "step": 4820
    },
    {
      "epoch": 18.157894736842106,
      "grad_norm": 1.64207923412323,
      "learning_rate": 9.210526315789474e-05,
      "loss": 0.3056,
      "step": 4830
    },
    {
      "epoch": 18.195488721804512,
      "grad_norm": 1.9767228364944458,
      "learning_rate": 9.022556390977444e-05,
      "loss": 0.2983,
      "step": 4840
    },
    {
      "epoch": 18.23308270676692,
      "grad_norm": 1.3894314765930176,
      "learning_rate": 8.834586466165413e-05,
      "loss": 0.3253,
      "step": 4850
    },
    {
      "epoch": 18.270676691729324,
      "grad_norm": 1.7696506977081299,
      "learning_rate": 8.646616541353383e-05,
      "loss": 0.3103,
      "step": 4860
    },
    {
      "epoch": 18.30827067669173,
      "grad_norm": 0.4969039261341095,
      "learning_rate": 8.458646616541353e-05,
      "loss": 0.3312,
      "step": 4870
    },
    {
      "epoch": 18.345864661654137,
      "grad_norm": 2.5659022331237793,
      "learning_rate": 8.270676691729323e-05,
      "loss": 0.3112,
      "step": 4880
    },
    {
      "epoch": 18.383458646616543,
      "grad_norm": 1.4159573316574097,
      "learning_rate": 8.082706766917294e-05,
      "loss": 0.3657,
      "step": 4890
    },
    {
      "epoch": 18.42105263157895,
      "grad_norm": 1.3703391551971436,
      "learning_rate": 7.894736842105263e-05,
      "loss": 0.3496,
      "step": 4900
    },
    {
      "epoch": 18.458646616541355,
      "grad_norm": 1.9128724336624146,
      "learning_rate": 7.706766917293233e-05,
      "loss": 0.2878,
      "step": 4910
    },
    {
      "epoch": 18.49624060150376,
      "grad_norm": 0.9588871598243713,
      "learning_rate": 7.518796992481203e-05,
      "loss": 0.3081,
      "step": 4920
    },
    {
      "epoch": 18.533834586466167,
      "grad_norm": 1.2794467210769653,
      "learning_rate": 7.330827067669172e-05,
      "loss": 0.3221,
      "step": 4930
    },
    {
      "epoch": 18.571428571428573,
      "grad_norm": 1.7814576625823975,
      "learning_rate": 7.142857142857142e-05,
      "loss": 0.3129,
      "step": 4940
    },
    {
      "epoch": 18.60902255639098,
      "grad_norm": 0.7928441762924194,
      "learning_rate": 6.954887218045113e-05,
      "loss": 0.3131,
      "step": 4950
    },
    {
      "epoch": 18.646616541353385,
      "grad_norm": 2.2993407249450684,
      "learning_rate": 6.766917293233083e-05,
      "loss": 0.3184,
      "step": 4960
    },
    {
      "epoch": 18.68421052631579,
      "grad_norm": 0.8613026738166809,
      "learning_rate": 6.578947368421052e-05,
      "loss": 0.2986,
      "step": 4970
    },
    {
      "epoch": 18.721804511278194,
      "grad_norm": 0.5104114413261414,
      "learning_rate": 6.390977443609022e-05,
      "loss": 0.2616,
      "step": 4980
    },
    {
      "epoch": 18.7593984962406,
      "grad_norm": 1.4113080501556396,
      "learning_rate": 6.203007518796992e-05,
      "loss": 0.3393,
      "step": 4990
    },
    {
      "epoch": 18.796992481203006,
      "grad_norm": 0.9072999358177185,
      "learning_rate": 6.015037593984962e-05,
      "loss": 0.3253,
      "step": 5000
    },
    {
      "epoch": 18.834586466165412,
      "grad_norm": 1.0990158319473267,
      "learning_rate": 5.827067669172932e-05,
      "loss": 0.2878,
      "step": 5010
    },
    {
      "epoch": 18.872180451127818,
      "grad_norm": 1.1555484533309937,
      "learning_rate": 5.639097744360902e-05,
      "loss": 0.3256,
      "step": 5020
    },
    {
      "epoch": 18.909774436090224,
      "grad_norm": 1.9910576343536377,
      "learning_rate": 5.451127819548872e-05,
      "loss": 0.3211,
      "step": 5030
    },
    {
      "epoch": 18.94736842105263,
      "grad_norm": 2.1952056884765625,
      "learning_rate": 5.263157894736842e-05,
      "loss": 0.3222,
      "step": 5040
    },
    {
      "epoch": 18.984962406015036,
      "grad_norm": 1.1681838035583496,
      "learning_rate": 5.075187969924812e-05,
      "loss": 0.2926,
      "step": 5050
    },
    {
      "epoch": 19.0,
      "eval_accuracy": 0.8583333333333333,
      "eval_loss": 0.32657209038734436,
      "eval_runtime": 22.3378,
      "eval_samples_per_second": 134.302,
      "eval_steps_per_second": 8.416,
      "step": 5054
    },
    {
      "epoch": 19.022556390977442,
      "grad_norm": 1.410074234008789,
      "learning_rate": 4.887218045112782e-05,
      "loss": 0.3238,
      "step": 5060
    },
    {
      "epoch": 19.06015037593985,
      "grad_norm": 0.9015202522277832,
      "learning_rate": 4.6992481203007515e-05,
      "loss": 0.291,
      "step": 5070
    },
    {
      "epoch": 19.097744360902254,
      "grad_norm": 4.580624103546143,
      "learning_rate": 4.511278195488722e-05,
      "loss": 0.2886,
      "step": 5080
    },
    {
      "epoch": 19.13533834586466,
      "grad_norm": 2.7104899883270264,
      "learning_rate": 4.3233082706766916e-05,
      "loss": 0.3167,
      "step": 5090
    },
    {
      "epoch": 19.172932330827066,
      "grad_norm": 1.2844008207321167,
      "learning_rate": 4.135338345864661e-05,
      "loss": 0.323,
      "step": 5100
    },
    {
      "epoch": 19.210526315789473,
      "grad_norm": 0.5374278426170349,
      "learning_rate": 3.9473684210526316e-05,
      "loss": 0.3003,
      "step": 5110
    },
    {
      "epoch": 19.24812030075188,
      "grad_norm": 1.7486168146133423,
      "learning_rate": 3.759398496240601e-05,
      "loss": 0.2886,
      "step": 5120
    },
    {
      "epoch": 19.285714285714285,
      "grad_norm": 1.8387694358825684,
      "learning_rate": 3.571428571428571e-05,
      "loss": 0.3582,
      "step": 5130
    },
    {
      "epoch": 19.32330827067669,
      "grad_norm": 1.3902636766433716,
      "learning_rate": 3.3834586466165414e-05,
      "loss": 0.3113,
      "step": 5140
    },
    {
      "epoch": 19.360902255639097,
      "grad_norm": 2.06060528755188,
      "learning_rate": 3.195488721804511e-05,
      "loss": 0.3616,
      "step": 5150
    },
    {
      "epoch": 19.398496240601503,
      "grad_norm": 10.408527374267578,
      "learning_rate": 3.007518796992481e-05,
      "loss": 0.2991,
      "step": 5160
    },
    {
      "epoch": 19.43609022556391,
      "grad_norm": 1.615169882774353,
      "learning_rate": 2.819548872180451e-05,
      "loss": 0.3311,
      "step": 5170
    },
    {
      "epoch": 19.473684210526315,
      "grad_norm": 1.2074916362762451,
      "learning_rate": 2.631578947368421e-05,
      "loss": 0.3254,
      "step": 5180
    },
    {
      "epoch": 19.51127819548872,
      "grad_norm": 1.0112570524215698,
      "learning_rate": 2.443609022556391e-05,
      "loss": 0.2986,
      "step": 5190
    },
    {
      "epoch": 19.548872180451127,
      "grad_norm": 1.2584431171417236,
      "learning_rate": 2.255639097744361e-05,
      "loss": 0.3494,
      "step": 5200
    },
    {
      "epoch": 19.586466165413533,
      "grad_norm": 1.8810992240905762,
      "learning_rate": 2.0676691729323306e-05,
      "loss": 0.3271,
      "step": 5210
    },
    {
      "epoch": 19.62406015037594,
      "grad_norm": 1.6224550008773804,
      "learning_rate": 1.8796992481203007e-05,
      "loss": 0.3416,
      "step": 5220
    },
    {
      "epoch": 19.661654135338345,
      "grad_norm": 0.9997999668121338,
      "learning_rate": 1.6917293233082707e-05,
      "loss": 0.2814,
      "step": 5230
    },
    {
      "epoch": 19.69924812030075,
      "grad_norm": 1.145385980606079,
      "learning_rate": 1.5037593984962406e-05,
      "loss": 0.2998,
      "step": 5240
    },
    {
      "epoch": 19.736842105263158,
      "grad_norm": 1.294013500213623,
      "learning_rate": 1.3157894736842104e-05,
      "loss": 0.3046,
      "step": 5250
    },
    {
      "epoch": 19.774436090225564,
      "grad_norm": 0.6900136470794678,
      "learning_rate": 1.1278195488721805e-05,
      "loss": 0.2872,
      "step": 5260
    },
    {
      "epoch": 19.81203007518797,
      "grad_norm": 1.4658068418502808,
      "learning_rate": 9.398496240601503e-06,
      "loss": 0.2816,
      "step": 5270
    },
    {
      "epoch": 19.849624060150376,
      "grad_norm": 1.424652099609375,
      "learning_rate": 7.518796992481203e-06,
      "loss": 0.2756,
      "step": 5280
    },
    {
      "epoch": 19.887218045112782,
      "grad_norm": 1.223695158958435,
      "learning_rate": 5.639097744360902e-06,
      "loss": 0.297,
      "step": 5290
    },
    {
      "epoch": 19.924812030075188,
      "grad_norm": 0.6038671731948853,
      "learning_rate": 3.7593984962406014e-06,
      "loss": 0.3223,
      "step": 5300
    },
    {
      "epoch": 19.962406015037594,
      "grad_norm": 1.7266173362731934,
      "learning_rate": 1.8796992481203007e-06,
      "loss": 0.307,
      "step": 5310
    },
    {
      "epoch": 20.0,
      "grad_norm": 1.4942960739135742,
      "learning_rate": 0.0,
      "loss": 0.318,
      "step": 5320
    },
    {
      "epoch": 20.0,
      "eval_accuracy": 0.8553333333333333,
      "eval_loss": 0.32816383242607117,
      "eval_runtime": 22.5564,
      "eval_samples_per_second": 133.0,
      "eval_steps_per_second": 8.335,
      "step": 5320
    },
    {
      "epoch": 20.0,
      "step": 5320,
      "total_flos": 2.634798489587712e+19,
      "train_loss": 0.4171075513040213,
      "train_runtime": 3767.2098,
      "train_samples_per_second": 90.252,
      "train_steps_per_second": 1.412
    }
  ],
  "logging_steps": 10,
  "max_steps": 5320,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 20,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2.634798489587712e+19,
  "train_batch_size": 64,
  "trial_name": null,
  "trial_params": null
}
